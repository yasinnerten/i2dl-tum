{"cells":[{"cell_type":"markdown","metadata":{"id":"9CALuVmNMNkM"},"source":["# Autoencoder for MNIST\n","\n","Welcome to this notebook where you'll be training an autoencoder using the MNIST dataset, which comprises handwritten digits. This exercise is the last where we present you with a structured skeleton to work with. However, in following exercises, we will only provide you with the dataset, task, and a test scenario, enabling you to test your skills and compete with your peers on our leaderboards. Get ready to dive in and showcase your deep learning expertise!\n","\n","\n","## Your task:\n","\n","Autoencoders have various applications, including unsupervised pretraining using unlabeled data, followed by fine-tuning the encoder with labeled data. This approach can greatly enhance performance when there is only a little amount of labeled data but a lot of unlabeled data available.\n","\n","In this exercise, you will use the MNIST dataset, consisting of 60,000 images of handwritten digits. However, not all the image labels are available to you. Your first objective is to train an autoencoder to accurately reproduce these unlabeled images.\n","\n","Afterwards, you will transfer the weights of the pretrained encoder and perform fine-tuning on a classifier using the available labeled data. This technique is commonly known as **transfer learning**, which allows you to leverage the knowledge gained from the autoencoder to improve the classification of the handwritten digits."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":101,"status":"ok","timestamp":1767639117133,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"XcU9f4APMNkT"},"outputs":[],"source":["# For automatic file reloading as usual\n","%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"Xb9dFU2EMNkW"},"source":["## (Optional) Mount folder in Colab\n","\n","Uncomment the following cell to mount your gdrive if you are using the notebook in google colab:"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20797,"status":"ok","timestamp":1767639137936,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"TRr4E4YVMNkW","outputId":"66bfcb95-e2b8-43fe-a0c9-b4c597931268"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["# Use the following lines if you want to use Google Colab\n","# We presume you created a folder \"i2dl\" within your main drive folder, and put the exercise there.\n","# NOTE: terminate all other colab sessions that use GPU!\n","# NOTE 2: Make sure the correct exercise folder (e.g exercise_08) is given.\n","\n","# from google.colab import drive\n","# import os\n","\n","\n","from google.colab import drive\n","import os\n","gdrive_path='/content/gdrive/MyDrive/i2dl/exercise_08'\n","\n","# This will mount your google drive under 'MyDrive'\n","drive.mount('/content/gdrive', force_remount=True)\n","# In order to access the files in this notebook we have to navigate to the correct folder\n","os.chdir(gdrive_path)\n","# Check manually if all files are present"]},{"cell_type":"markdown","metadata":{"id":"JzDQg-kDMNkY"},"source":["### Set up PyTorch environment in colab\n","- (OPTIONAL) Enable GPU via Runtime --> Change runtime type --> GPU\n","- Uncomment the following cell if you are using the notebook in google colab:"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":389351,"status":"ok","timestamp":1767639527288,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"pIUdsXeXMNkZ","outputId":"67a86faf-3297-40cd-9272-292daa486f33"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==2.0.1+cu118\n","  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.15.2+cu118\n","  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==2.0.2+cu118\n","  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchtext==0.15.2\n","  Downloading https://download.pytorch.org/whl/torchtext-0.15.2%2Bcpu-cp311-cp311-linux_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (4.14.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.1.6)\n","Collecting triton==2.0.0 (from torch==2.0.1+cu118)\n","  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (2.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (2.32.3)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (11.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (4.67.1)\n","Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n","  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.4.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.31.6)\n","Collecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2025.7.14)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\n","Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, triton, torch, torchdata, torchvision, torchtext, torchaudio\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.11.0\n","    Uninstalling torchdata-0.11.0:\n","      Successfully uninstalled torchdata-0.11.0\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.21.0+cu124\n","    Uninstalling torchvision-0.21.0+cu124:\n","      Successfully uninstalled torchvision-0.21.0+cu124\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.6.0+cu124\n","    Uninstalling torchaudio-2.6.0+cu124:\n","      Successfully uninstalled torchaudio-2.6.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.6.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-18.1.8 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchdata-0.6.1 torchtext-0.15.2+cpu torchvision-0.15.2+cu118 triton-2.0.0\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.73.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.8.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard) (24.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.6.0-py3-none-any.whl.metadata (21 kB)\n","Collecting torch>=2.1.0 (from pytorch-lightning)\n","  Downloading torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n","Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n","Collecting torchmetrics>0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n","Requirement already satisfied: typing-extensions>4.5.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.14.1)\n","Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n","Collecting sympy>=1.13.3 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n","Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n","Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n","Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n","Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.5.1 (from torch>=2.1.0->pytorch-lightning)\n","  Downloading triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>0.7.0->pytorch-lightning) (2.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n","Downloading pytorch_lightning-2.6.0-py3-none-any.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n","Downloading torch-2.9.1-cp311-cp311-manylinux_2_28_x86_64.whl (899.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.8/899.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m152.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/6e/89/f7a07dc961b60645dbbf42e80f2bc85ade7feb9a491b11a1e973aa00071f/nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\u001b[0m\u001b[33m\n","\u001b[0mDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (124.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.5.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.4/170.4 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m147.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchmetrics, pytorch-lightning\n","  Attempting uninstall: nvidia-cusparselt-cu12\n","    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n","    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n","      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.0.0\n","    Uninstalling triton-2.0.0:\n","      Successfully uninstalled triton-2.0.0\n","  Attempting uninstall: sympy\n","    Found existing installation: sympy 1.13.1\n","    Uninstalling sympy-1.13.1:\n","      Successfully uninstalled sympy-1.13.1\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1+cu118\n","    Uninstalling torch-2.0.1+cu118:\n","      Successfully uninstalled torch-2.0.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.9.1 which is incompatible.\n","torchtext 0.15.2+cpu requires torch==2.0.1, but you have torch 2.9.1 which is incompatible.\n","torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.9.1 which is incompatible.\n","torchdata 0.6.1 requires torch==2.0.1, but you have torch 2.9.1 which is incompatible.\n","fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.9.1 which is incompatible.\n","torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.6.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lightning-utilities-0.15.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.3.20 nvidia-nvtx-cu12-12.8.90 pytorch-lightning-2.6.0 sympy-1.14.0 torch-2.9.1 torchmetrics-1.8.2 triton-3.5.1\n"]}],"source":["# Optional: install correct libraries in google colab\n","!python -m pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 torchtext==0.15.2 -f https://download.pytorch.org/whl/torch_stable.html\n","!python -m pip install tensorboard\n","!python -m pip install pytorch-lightning"]},{"cell_type":"markdown","metadata":{"id":"hEDWAZ7-ZA4E"},"source":["# Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31751,"status":"ok","timestamp":1767639559042,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"dJCiVLV5o9QO","outputId":"23babdf3-2c89-4418-e655-62d9320f9437","scrolled":true},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /usr/local/lib/python3.11/dist-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n","  warn(\n"]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import os, sys\n","import shutil\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","from exercise_code.image_folder_dataset import ImageFolderDataset\n","from torch.utils.tensorboard import SummaryWriter\n","from time import sleep\n","from tqdm import tqdm\n","from exercise_code.tests.base_tests import bcolors\n","\n","torch.manual_seed(42)\n","\n","os.environ['KMP_DUPLICATE_LIB_OK']='True' # To prevent the kernel from dying."]},{"cell_type":"markdown","metadata":{"id":"dvaj6myXS7nN"},"source":["<div class=\"alert alert-warning\">\n","    <h3>Note: Google Colab</h3>\n","    <p>\n","In case you don't have a GPU, you can run this notebook on Google Colab where you can access a GPU for free, but, of course, you can also run this notebook on your CPU.\n","         </p>\n","</div>"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107,"status":"ok","timestamp":1767639559152,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"VWgm75NnS9hr","outputId":"568a9fe7-e05c-4a5c-d412-9506e06d5484","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["You are using the following device:  cuda:0\n"]}],"source":["# This will set the device on which to run the code, which defaults to the CPU.\n","# If you have an Nvidia GPU, it will use that with cuda\n","# For Apple Silicon, you can try to use the \"mps\" device by commenting in line 8.\n","#  But it is not guaranteed to work and sometimes the CPU performs better.\n","\n","device = torch.device(\n","    \"cuda:0\" if torch.cuda.is_available() else\n","    \"mps\" if torch.backends.mps.is_available() else\n","    \"cpu\"\n",")\n","\n","print('You are using the following device: ', device)"]},{"cell_type":"markdown","metadata":{"id":"Pm_rTAPnpsUo"},"source":["## Setup TensorBoard\n","\n","In the previous exercise (Exercise 07), you learned how to use TensorBoard effectively. Let's use it again to enhance the convenience of debugging your network and the training process. Throughout this notebook, feel free to implement additional logs or visualizations into your TensorBoard, further improving your analysis and understanding of the network's behavior."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":58,"status":"ok","timestamp":1767639559211,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"QbAJFyHkMNke"},"outputs":[],"source":["################# COLAB ONLY #################\n","# %load_ext tensorboard\n","# %tensorboard --logdir=./ --port 6006\n","\n","# Use the cmd for less trouble, if you can. From the working directory, run: tensorboard --logdir=./ --port 6006"]},{"cell_type":"markdown","metadata":{"id":"t-Yt2KRiMNkf"},"source":["# 1. The MNIST Dataset\n","\n","First, let's download the MNIST dataset. As mentioned at the beginning of this notebook, MNIST is a dataset of 60,000 images depicting handwritten digits. However, labeling such a large dataset can be a costly process, leaving us in a challenging situation.\n","\n","To overcome this, a practical approach is to label a small subset of the images. Let's consider a scenario where you have hired another student to perform the labeling task for you. After some time, you have been provided with 300 labeled images. Out of these, 100 images will be used for training, another 100 for validation, and the remaining 100 for testing. Undoubtedly, this poses a challenge due to the limited number of labeled samples.\n","\n","Now, you have the flexibility to define any transforms that you deem necessary, either at this point or at a later stage. However, it's important to note that during the final evaluation on the server, no transformations will be applied to the test set.\n","\n","Feel free to experiment with various transforms as you proceed (you can also pass without any transforms).\n","\n","\n","**Note**: We do **not** apply any transformations or normalization to the test set at the time of final evaluation on our server."]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13541,"status":"ok","timestamp":1767639572753,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"U5_eopjbMNkf","outputId":"f0cc5e81-312f-4927-abb4-b65ba5996459","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n","'--force_download=True'\n","https://i2dl.vc.in.tum.de/static/data/mnist.zip\n","Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n","'--force_download=True'\n","https://i2dl.vc.in.tum.de/static/data/mnist.zip\n","Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n","'--force_download=True'\n","https://i2dl.vc.in.tum.de/static/data/mnist.zip\n","Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n","'--force_download=True'\n","https://i2dl.vc.in.tum.de/static/data/mnist.zip\n","Found dataset folder. Skipped downloading. If you face issues, please re-download the dataset using\n","'--force_download=True'\n","https://i2dl.vc.in.tum.de/static/data/mnist.zip\n"]}],"source":["########################################################################\n","# TODO: Feel free to define transforms (Only data augmentation)        #\n","########################################################################\n","\n","# Data augmentation for training - helps with limited labeled data\n","# Note: Images are already tensors from .pt files (shape: 28x28 or 1x28x28)\n","def augment_image(img):\n","    \"\"\"Apply data augmentation to a tensor image\"\"\"\n","    # Ensure image is in correct format (add channel dimension if needed)\n","    if img.dim() == 2:\n","        img = img.unsqueeze(0)  # Add channel dimension: (28, 28) -> (1, 28, 28)\n","\n","    img = img.clone()\n","\n","    # Random rotation (-10 to +10 degrees) - subtle for digits\n","    if np.random.random() > 0.5:  # Apply 50% of the time\n","        angle = np.random.uniform(-10, 10)\n","        img = transforms.functional.rotate(img, angle, interpolation=transforms.InterpolationMode.BILINEAR, fill=0)\n","\n","    # Random translation (up to 2 pixels)\n","    if np.random.random() > 0.5:  # Apply 50% of the time\n","        translate = (np.random.uniform(-2, 2), np.random.uniform(-2, 2))\n","        img = transforms.functional.affine(img, angle=0, translate=translate, scale=1.0, shear=0, fill=0)\n","\n","    # Random slight scaling (0.95 to 1.05)\n","    if np.random.random() > 0.5:  # Apply 50% of the time\n","        scale = np.random.uniform(0.95, 1.05)\n","        img = transforms.functional.affine(img, angle=0, translate=(0, 0), scale=scale, shear=0, fill=0)\n","\n","    # Remove channel dimension if it was added\n","    if img.shape[0] == 1:\n","        img = img.squeeze(0)\n","\n","    return img\n","\n","# Transform for training (with augmentation)\n","transform_train = transforms.Compose([\n","    transforms.Lambda(lambda x: augment_image(x) if isinstance(x, torch.Tensor) else x)\n","])\n","\n","# Transform for validation/test (no augmentation)\n","transform_val = transforms.Compose([])\n","\n","########################################################################\n","#                           END OF YOUR CODE                           #\n","########################################################################\n","\n","i2dl_exercises_path = os.path.dirname(os.path.abspath(os.getcwd()))\n","mnist_root = os.path.join(i2dl_exercises_path, \"datasets\", \"mnist\")\n","\n","# Use augmentation for training, no augmentation for validation/test\n","train_100_dataset = ImageFolderDataset(root=mnist_root,images='train_images.pt',labels='train_labels.pt',force_download=False,verbose=True,transform=transform_train)\n","val_100_dataset = ImageFolderDataset(root=mnist_root,images='val_images.pt',labels='val_labels.pt',force_download=False,verbose=True,transform=transform_val)\n","test_100_dataset = ImageFolderDataset(root=mnist_root,images='test_images.pt',labels='test_labels.pt',force_download=False,verbose=True,transform=transform_val)\n","\n","# We also set up the unlabeled images which we will use later (no augmentation for autoencoder)\n","unlabeled_train = ImageFolderDataset(root=mnist_root,images='unlabeled_train_images.pt',force_download=False,verbose=True,transform=transform_val)\n","unlabeled_val = ImageFolderDataset(root=mnist_root,images='unlabeled_val_images.pt',force_download=False,verbose=True,transform=transform_val)"]},{"cell_type":"markdown","metadata":{"id":"zwrT1ckAMNkg"},"source":["The dataset consists of tuples of 28x28 pixel PIL images and a label that is an integer from 0 to 9.\n","\n","Let's turn a few of the images into numpy arrays, to look at their shape and visualize them and see if the labels we paid for are correct."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":1124,"status":"ok","timestamp":1767639573879,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"k7ct1J2CMNkh","outputId":"18d4db74-1c2d-4a43-cb97-b445957296a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["The shape of our greyscale images:  (28, 28)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1600x1600 with 10 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["plt.rcParams['figure.figsize'] = (16,16) # Make the figures a bit bigger\n","\n","indices_arr = [83, 98, 92, 99, 78, 97, 90, 95, 93, 96]\n","for i, index in enumerate(indices_arr):\n","    image = np.array(train_100_dataset[index][0].squeeze()) # get the image of the data sample\n","    label = train_100_dataset[index][1] # get the label of the data sample\n","    plt.subplot(1, 10, i + 1)\n","    plt.imshow(image, cmap='gray', interpolation='none')\n","    plt.title(\"Class {}\".format(label))\n","\n","plt.tight_layout()\n","print('The shape of our greyscale images: ', image.shape)"]},{"cell_type":"markdown","metadata":{"id":"V9sz_lHyqJoj"},"source":["<div class=\"alert alert-warning\">\n","    <h3>Note: Starting Simple</h3>\n","    <p>\n","Regardless of the size of the dataset, the first step is to evaluate the performance of a simple classifier. It is advisable to always start with a straightforward approach when tackling a problem and gradually build upon it to determine which changes yield improvements.</p>\n","</div>\n","\n","# 2. A Simple Classifier\n","\n","In `exercise_code/models.py`, we prepared all classes for you, which you will finalize throughout the notebook to build an Autoencoder and an image classifier with PyTorch.\n","\n","<!-- In case image does not show, uncomment the following:\n"," ![network_split](img/network_split.png)\n"," -->\n","<img name=\"network_split\" src=\"https://i2dl.vc.in.tum.de/static/images/exercise_08/network_split.png\">\n","\n","\n","## 2.1 The Encoder\n","\n","Unlike previous models, we are going to split up the model into two parts: the `encoder` and the `classifier`. The `classifier` has a fixed task, generating predictions given a one-dimensional input. On the other hand, the `encoder`'s task is to extract meaningful information from the input, enabling the classifier to make accurate decisions.\n","\n","For now, both networks will be similar in design and consist of linear layers coupled with auxiliary layers. This split-up will be relevant later, e.g., by using convolutional layers, which are introduced in the lecture. We are going to set up the `encoder` now.\n","\n","Think about a good network architecture. You have complete freedom in this regard and can devise any network structure you think might be fitting. (\\*)\n","\n","Have a look at the documentation of `torch.nn` at https://pytorch.org/docs/stable/nn.html to learn how to use this module in order to build your network!\n","\n","Then implement your architecture: initialize it in `__init__()` and assign it to `self.model`. This is particularly easy using `nn.Sequential()`, where you only have to pass the list of your layers.\n","\n","To make your model customizable and support parameter search, do not use hardcoded hyperparameters - instead, pass them as a simple dictionary `hparams` (here, `n_hidden` is the number of neurons in the hidden layer) when initializing `models`.\n","\n","Here is a simple example:\n","\n","```python\n","        self.model = nn.Sequential(\n","            nn.Linear(input_size, self.hparams[\"n_hidden\"]),\n","            nn.ReLU(),            \n","            nn.Linear(self.hparams[\"n_hidden\"], num_classes)\n","        )\n","```\n","\n","Have a look at the forward path in `forward(self, x)`, which is so easy that you don't need to implement it yourself.\n","\n","As PyTorch automatically computes the gradients, that's all you need to do! There is no need to manually calculate derivatives for the backward paths anymore! :)\n","\n","\n","____\n","\\* *The size of your final model must be less than 20 MB, which is approximately equivalent to 5 Mio. params. Note that this limit is quite lenient, you will probably need much fewer parameters!*\n","\n","*In order to keep things simple, you should only use fully connected layers for this task, as we need to revert the encoder architecture later on in the notebook.*\n","\n","<div class=\"alert alert-info\">\n","    <h3>Task: Implement</h3>\n","    <p>Implement the <code>Encoder</code> class initialization in <code>exercise_code/models.py</code>.\n","    </p>\n","</div>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jNf7FrvwMNki"},"source":["## 2.2 The Classifier\n","\n","Now let's implement the classifier. The classifier will utilize the encoder that you have defined in the above cell. By looking at `Classifier.forward`, you can see that we are essentially concatenating the `classifier`and the `encoder` together. Therefore, it is crucial to ensure that the input shape of the classifier matches the output shape of the encoder you implemented above\n","\n","<div class=\"alert alert-info\">\n","    <h3>Task: Implement</h3>\n","    <p>1. Implement the <code>Classifier</code> class network initialization in <code>exercise_code/models.py</code>.\n","    </p>\n","    <p>2. Define in the next cell your hyperparameters in a dictionary called 'hparams'.\n","    </p>\n","</div>"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1767639573893,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"AawbvD1rMNkj"},"outputs":[],"source":["\n","########################################################################\n","# TODO: Define your hyper parameters here!                             #\n","########################################################################\n","\n","hparams = {\n","    # Model architecture - Enhanced with deeper networks and larger latent space\n","    'n_hidden_encoder': 512,      # First hidden layer size for encoder (increased)\n","    'n_hidden_encoder2': 256,     # Second hidden layer size for encoder (increased)\n","    'n_hidden_encoder3': 128,     # Third hidden layer size for encoder (increased)\n","    'latent_dim': 64,             # Latent space dimension (increased from 20 to 64 for better representations)\n","    'n_hidden_classifier': 256,   # First hidden layer size for classifier (increased)\n","    'n_hidden_classifier2': 128,  # Second hidden layer size for classifier (increased)\n","    'n_hidden_classifier3': 64,   # Third hidden layer size for classifier (added)\n","\n","    # Regularization\n","    'dropout_rate': 0.25,         # Dropout rate for encoder/decoder (slightly reduced)\n","    'classifier_dropout': 0.35,   # Dropout rate for classifier (slightly reduced)\n","    'weight_decay': 1e-4,         # Weight decay for L2 regularization (increased)\n","    'label_smoothing': 0.1,       # Label smoothing for better generalization\n","\n","    # Training parameters\n","    'learning_rate': 8e-4,        # Learning rate for optimizer (slightly reduced)\n","    'batch_size': 128,            # Batch size for training\n","    'epochs': 100,                # Maximum number of epochs (increased, early stopping will stop earlier)\n","\n","    # Device\n","    'device': device\n","}\n","\n","########################################################################\n","#                           END OF YOUR CODE                           #\n","########################################################################"]},{"cell_type":"markdown","metadata":{"id":"bOYbUg8lAmgU"},"source":["\n","## 2.3 Optimizer\n","Lastly, implement the function `set_optimizer` to define your optimizer. Here the documentation of `torch.optim` at https://pytorch.org/docs/stable/optim.html might be helpful.\n","\n","<div class=\"alert alert-info\">\n","    <h3>Task: Implement</h3>\n","    <p>Implement the <code>set_optimizer</code> method of the <code>Classifier</code> in <code>exercise_code/models.py</code>.\n","    </p>\n","</div>\n"]},{"cell_type":"markdown","metadata":{"id":"xrUfa-a7MNkk"},"source":["## 2.4 Training & Validation Step\n","\n","<div class=\"alert alert-success\">\n","    <h3>Task: Check Code</h3>\n","    <p> Let's take a closer look at the training pipeline outlined below. It is explicitly written here in its entirety to provide you with a comprehensive understanding of its structure. Additionally, you can refer back to this pipeline whenever you encounter any uncertainties or need guidance.\n"," </p>\n","</div>\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1767639574229,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"NY_lLaNWMNkk"},"outputs":[],"source":[" # One of the most crucial things in deep learning is to understand the training pipeline:\n"," # 1. Forward()          --> The forward pass of the network, to calculate the currnent loss.\n"," # 2. Backward()         --> The backward pass of the network, to calculate the gradients w.r.t the loss, calculated in the previous stage.\n"," # 3. Optimizer_step()   --> Update the weights w.r.t their corresponding gradients and the learnign rate.\n","\n","def create_tqdm_bar(iterable, desc):\n","    return tqdm(enumerate(iterable),total=len(iterable), ncols=150, desc=desc)\n","\n","\n","def train_classifier(classifier, train_loader, val_loader, loss_func, tb_logger, epochs=10, name=\"default\",\n","                     early_stopping_patience=10, min_delta=1e-6):\n","    \"\"\"\n","    Train the classifier for a number of epochs with early stopping.\n","\n","    Args:\n","        early_stopping_patience: Number of epochs to wait before stopping if no improvement\n","        min_delta: Minimum change to qualify as an improvement\n","    \"\"\"\n","    optimizer = classifier.optimizer\n","    classifier = classifier.to(device)\n","\n","    # Early stopping variables\n","    best_val_loss = float('inf')\n","    patience_counter = 0\n","    best_model_state = None\n","\n","    # Learning rate scheduler\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n","    )\n","\n","    current_lr = optimizer.param_groups[0]['lr']\n","\n","    validation_loss = 0\n","    for epoch in range(epochs):\n","\n","        training_loss = 0\n","\n","        # Training stage, where we want to update the parameters.\n","        classifier.train()  # Set the model to training mode\n","\n","        # Create a progress bar for the training loop.\n","        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch + 1}/{epochs}]')\n","        for train_iteration, batch in training_loop:\n","            optimizer.zero_grad() # Reset the gradients - VERY important! Otherwise they accumulate.\n","            images, labels = batch # Get the images and labels from the batch, in the fashion we defined in the dataset and dataloader.\n","            images, labels = images.to(device), labels.to(device) # Send the data to the device (GPU or CPU) - it has to be the same device as the model.\n","\n","            # Flatten the images to a vector. This is done because the classifier expects a vector as input.\n","            # Could also be done by reshaping the images in the dataset.\n","            images = images.view(images.shape[0], -1)\n","\n","            pred = classifier(images) # Stage 1: Forward().\n","            loss = loss_func(pred, labels) # Compute the loss over the predictions and the ground truth.\n","            loss.backward()  # Stage 2: Backward().\n","            optimizer.step() # Stage 3: Update the parameters.\n","\n","            training_loss += loss.item()\n","\n","            # Update the progress bar.\n","            training_loop.set_postfix(curr_train_loss = \"{:.8f}\".format(training_loss / (train_iteration + 1)), val_loss = \"{:.8f}\".format(validation_loss))\n","\n","            # Update the tensorboard logger.\n","            tb_logger.add_scalar(f'classifier_{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n","            sleep(0.1) # Remove this line if you want to see the progress bar faster.\n","\n","        # Validation stage, where we don't want to update the parameters. Pay attention to the classifier.eval() line\n","        # and \"with torch.no_grad()\" wrapper.\n","        classifier.eval()\n","        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch + 1}/{epochs}]')\n","        validation_loss = 0\n","        with torch.no_grad():\n","            for val_iteration, batch in val_loop:\n","                images, labels = batch\n","                images, labels = images.to(device), labels.to(device)\n","\n","                images = images.view(images.shape[0], -1)\n","                pred = classifier(images)\n","                loss = loss_func(pred, labels)\n","                validation_loss += loss.item()\n","\n","                # Update the progress bar.\n","                val_loop.set_postfix(val_loss = \"{:.8f}\".format(validation_loss / (val_iteration + 1)))\n","\n","                # Update the tensorboard logger.\n","                tb_logger.add_scalar(f'classifier_{name}/val_loss', loss.item(), epoch * len(val_loader) + val_iteration)\n","                sleep(0.1) # Remove this line if you want to see the progress bar faster.\n","\n","        # This value is used for the progress bar of the training loop.\n","        validation_loss /= len(val_loader)\n","\n","        # Learning rate scheduling\n","        old_lr = optimizer.param_groups[0]['lr']\n","        scheduler.step(validation_loss)\n","        new_lr = optimizer.param_groups[0]['lr']\n","        if old_lr != new_lr:\n","            print(f\"Learning rate reduced from {old_lr:.6f} to {new_lr:.6f}\")\n","\n","        # Early stopping logic\n","        if validation_loss < best_val_loss - min_delta:\n","            best_val_loss = validation_loss\n","            patience_counter = 0\n","            # Save best model state\n","            best_model_state = {k: v.cpu().clone() for k, v in classifier.state_dict().items()}\n","            print(f\"Epoch {epoch+1}: Validation loss improved to {validation_loss:.6f}\")\n","        else:\n","            patience_counter += 1\n","            print(f\"Epoch {epoch+1}: No improvement. Patience: {patience_counter}/{early_stopping_patience}\")\n","\n","        # Early stopping check\n","        if patience_counter >= early_stopping_patience:\n","            print(f\"Early stopping triggered at epoch {epoch+1}. Restoring best model.\")\n","            classifier.load_state_dict(best_model_state)\n","            break\n","\n","    # Restore best model if early stopping didn't trigger\n","    if best_model_state is not None and patience_counter < early_stopping_patience:\n","        classifier.load_state_dict(best_model_state)\n","        print(\"Training completed. Best model restored.\")\n"]},{"cell_type":"markdown","metadata":{"id":"KVKLlwlyMNkl"},"source":["## 2.5 Fit Classification Model with Trainer\n","Now it's finally time to train your model.\n","Run the following cell to see the behold the magic of deep learning at play."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34130,"status":"ok","timestamp":1767639608368,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"uBGavq9cMNkl","outputId":"013a9852-e9d4-4955-caa4-42f3a0f965a3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using label smoothing: 0.1\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [1/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  1.78it/s, curr_train_loss=2.40507793, val_loss=0.00000000]\n","Validation Epoch [1/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.29it/s, val_loss=2.30923319]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Validation loss improved to 2.309233\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [2/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.70it/s, curr_train_loss=2.34677100, val_loss=2.30923319]\n","Validation Epoch [2/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.42it/s, val_loss=2.30910659]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: Validation loss improved to 2.309107\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [3/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.85it/s, curr_train_loss=2.34838939, val_loss=2.30910659]\n","Validation Epoch [3/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.28it/s, val_loss=2.30897999]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: Validation loss improved to 2.308980\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [4/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.67it/s, curr_train_loss=2.33284163, val_loss=2.30897999]\n","Validation Epoch [4/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.34it/s, val_loss=2.30925512]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: No improvement. Patience: 1/15\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [5/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.56it/s, curr_train_loss=2.37011480, val_loss=2.30925512]\n","Validation Epoch [5/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.27it/s, val_loss=2.30905724]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: No improvement. Patience: 2/15\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [6/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  6.07it/s, curr_train_loss=2.26660109, val_loss=2.30905724]\n","Validation Epoch [6/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.40it/s, val_loss=2.30867648]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: Validation loss improved to 2.308676\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [7/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.64it/s, curr_train_loss=2.23944044, val_loss=2.30867648]\n","Validation Epoch [7/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.46it/s, val_loss=2.30770302]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: Validation loss improved to 2.307703\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [8/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.88it/s, curr_train_loss=2.24784565, val_loss=2.30770302]\n","Validation Epoch [8/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.33it/s, val_loss=2.30672336]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8: Validation loss improved to 2.306723\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [9/100]: 100%|██████████████████████████████████████████| 1/1 [00:00<00:00,  5.76it/s, curr_train_loss=2.24633980, val_loss=2.30672336]\n","Validation Epoch [9/100]: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.39it/s, val_loss=2.30537033]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: Validation loss improved to 2.305370\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [10/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.91it/s, curr_train_loss=2.18737698, val_loss=2.30537033]\n","Validation Epoch [10/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.33it/s, val_loss=2.30390477]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Validation loss improved to 2.303905\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [11/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.71it/s, curr_train_loss=2.26781464, val_loss=2.30390477]\n","Validation Epoch [11/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.36it/s, val_loss=2.30194569]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: Validation loss improved to 2.301946\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [12/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.48it/s, curr_train_loss=2.16245055, val_loss=2.30194569]\n","Validation Epoch [12/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.35it/s, val_loss=2.29915476]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12: Validation loss improved to 2.299155\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [13/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.86it/s, curr_train_loss=2.12823868, val_loss=2.29915476]\n","Validation Epoch [13/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.50it/s, val_loss=2.29614067]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13: Validation loss improved to 2.296141\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [14/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.16it/s, curr_train_loss=2.10427976, val_loss=2.29614067]\n","Validation Epoch [14/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.05it/s, val_loss=2.29212809]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14: Validation loss improved to 2.292128\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [15/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.85it/s, curr_train_loss=2.05960512, val_loss=2.29212809]\n","Validation Epoch [15/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.27it/s, val_loss=2.28718805]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15: Validation loss improved to 2.287188\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [16/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.98it/s, curr_train_loss=2.05775905, val_loss=2.28718805]\n","Validation Epoch [16/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.29it/s, val_loss=2.28070045]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16: Validation loss improved to 2.280700\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [17/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.83it/s, curr_train_loss=2.00778937, val_loss=2.28070045]\n","Validation Epoch [17/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.16it/s, val_loss=2.27217126]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17: Validation loss improved to 2.272171\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [18/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.02it/s, curr_train_loss=2.03555989, val_loss=2.27217126]\n","Validation Epoch [18/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.41it/s, val_loss=2.26124310]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18: Validation loss improved to 2.261243\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [19/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.94it/s, curr_train_loss=2.03667212, val_loss=2.26124310]\n","Validation Epoch [19/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.40it/s, val_loss=2.24789906]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19: Validation loss improved to 2.247899\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [20/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.99it/s, curr_train_loss=1.93147182, val_loss=2.24789906]\n","Validation Epoch [20/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.34it/s, val_loss=2.23325205]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20: Validation loss improved to 2.233252\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [21/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.54it/s, curr_train_loss=1.89876342, val_loss=2.23325205]\n","Validation Epoch [21/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.05it/s, val_loss=2.21558309]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21: Validation loss improved to 2.215583\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [22/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.17it/s, curr_train_loss=1.91693449, val_loss=2.21558309]\n","Validation Epoch [22/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.09it/s, val_loss=2.19494295]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22: Validation loss improved to 2.194943\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [23/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.89it/s, curr_train_loss=1.91432786, val_loss=2.19494295]\n","Validation Epoch [23/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.30it/s, val_loss=2.17413306]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23: Validation loss improved to 2.174133\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [24/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.75it/s, curr_train_loss=1.92206681, val_loss=2.17413306]\n","Validation Epoch [24/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.34it/s, val_loss=2.14860749]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24: Validation loss improved to 2.148607\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [25/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.75it/s, curr_train_loss=1.87575150, val_loss=2.14860749]\n","Validation Epoch [25/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.44it/s, val_loss=2.12428331]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25: Validation loss improved to 2.124283\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [26/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.22it/s, curr_train_loss=1.83911109, val_loss=2.12428331]\n","Validation Epoch [26/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.37it/s, val_loss=2.09871078]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26: Validation loss improved to 2.098711\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [27/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.90it/s, curr_train_loss=1.84856117, val_loss=2.09871078]\n","Validation Epoch [27/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.40it/s, val_loss=2.07240701]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27: Validation loss improved to 2.072407\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [28/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.56it/s, curr_train_loss=1.77707410, val_loss=2.07240701]\n","Validation Epoch [28/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.23it/s, val_loss=2.04748297]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28: Validation loss improved to 2.047483\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [29/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.83it/s, curr_train_loss=1.75472975, val_loss=2.04748297]\n","Validation Epoch [29/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.34it/s, val_loss=2.02077723]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29: Validation loss improved to 2.020777\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [30/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.14it/s, curr_train_loss=1.74006128, val_loss=2.02077723]\n","Validation Epoch [30/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.35it/s, val_loss=1.99693823]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30: Validation loss improved to 1.996938\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [31/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.77it/s, curr_train_loss=1.73592353, val_loss=1.99693823]\n","Validation Epoch [31/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.39it/s, val_loss=1.97196341]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31: Validation loss improved to 1.971963\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [32/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.72it/s, curr_train_loss=1.72436154, val_loss=1.97196341]\n","Validation Epoch [32/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.36it/s, val_loss=1.94767642]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32: Validation loss improved to 1.947676\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [33/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.40it/s, curr_train_loss=1.67590737, val_loss=1.94767642]\n","Validation Epoch [33/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.37it/s, val_loss=1.92465603]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33: Validation loss improved to 1.924656\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [34/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.05it/s, curr_train_loss=1.66079867, val_loss=1.92465603]\n","Validation Epoch [34/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.27it/s, val_loss=1.90306020]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34: Validation loss improved to 1.903060\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [35/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.62it/s, curr_train_loss=1.62834787, val_loss=1.90306020]\n","Validation Epoch [35/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.32it/s, val_loss=1.88270235]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35: Validation loss improved to 1.882702\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [36/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.07it/s, curr_train_loss=1.67769110, val_loss=1.88270235]\n","Validation Epoch [36/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.20it/s, val_loss=1.86321747]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36: Validation loss improved to 1.863217\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [37/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.83it/s, curr_train_loss=1.67264676, val_loss=1.86321747]\n","Validation Epoch [37/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.39it/s, val_loss=1.84204328]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37: Validation loss improved to 1.842043\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [38/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.91it/s, curr_train_loss=1.60646784, val_loss=1.84204328]\n","Validation Epoch [38/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.48it/s, val_loss=1.82458854]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38: Validation loss improved to 1.824589\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [39/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.03it/s, curr_train_loss=1.59989905, val_loss=1.82458854]\n","Validation Epoch [39/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.21it/s, val_loss=1.80814922]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39: Validation loss improved to 1.808149\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [40/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.04it/s, curr_train_loss=1.55604267, val_loss=1.80814922]\n","Validation Epoch [40/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.44it/s, val_loss=1.79260683]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40: Validation loss improved to 1.792607\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [41/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.54it/s, curr_train_loss=1.62639964, val_loss=1.79260683]\n","Validation Epoch [41/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.31it/s, val_loss=1.77733970]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41: Validation loss improved to 1.777340\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [42/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.85it/s, curr_train_loss=1.53020883, val_loss=1.77733970]\n","Validation Epoch [42/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.42it/s, val_loss=1.76154912]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42: Validation loss improved to 1.761549\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [43/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.84it/s, curr_train_loss=1.54616070, val_loss=1.76154912]\n","Validation Epoch [43/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.35it/s, val_loss=1.74854684]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43: Validation loss improved to 1.748547\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [44/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.83it/s, curr_train_loss=1.42366338, val_loss=1.74854684]\n","Validation Epoch [44/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.35it/s, val_loss=1.73472476]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44: Validation loss improved to 1.734725\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [45/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.78it/s, curr_train_loss=1.44335294, val_loss=1.73472476]\n","Validation Epoch [45/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.48it/s, val_loss=1.72064161]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45: Validation loss improved to 1.720642\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [46/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  6.00it/s, curr_train_loss=1.47719347, val_loss=1.72064161]\n","Validation Epoch [46/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.34it/s, val_loss=1.70635343]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46: Validation loss improved to 1.706353\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [47/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.24it/s, curr_train_loss=1.42514968, val_loss=1.70635343]\n","Validation Epoch [47/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.46it/s, val_loss=1.69314575]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47: Validation loss improved to 1.693146\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [48/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.72it/s, curr_train_loss=1.42768383, val_loss=1.69314575]\n","Validation Epoch [48/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.47it/s, val_loss=1.68124402]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48: Validation loss improved to 1.681244\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [49/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.93it/s, curr_train_loss=1.42391491, val_loss=1.68124402]\n","Validation Epoch [49/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.34it/s, val_loss=1.66775715]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49: Validation loss improved to 1.667757\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [50/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.79it/s, curr_train_loss=1.39696097, val_loss=1.66775715]\n","Validation Epoch [50/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.43it/s, val_loss=1.65579712]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50: Validation loss improved to 1.655797\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [51/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.97it/s, curr_train_loss=1.40122569, val_loss=1.65579712]\n","Validation Epoch [51/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.34it/s, val_loss=1.64159441]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51: Validation loss improved to 1.641594\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [52/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.47it/s, curr_train_loss=1.42467546, val_loss=1.64159441]\n","Validation Epoch [52/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.41it/s, val_loss=1.62725723]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52: Validation loss improved to 1.627257\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [53/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.49it/s, curr_train_loss=1.42527282, val_loss=1.62725723]\n","Validation Epoch [53/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.39it/s, val_loss=1.61248088]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53: Validation loss improved to 1.612481\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [54/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.30it/s, curr_train_loss=1.40905130, val_loss=1.61248088]\n","Validation Epoch [54/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.49it/s, val_loss=1.60163021]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54: Validation loss improved to 1.601630\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [55/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.69it/s, curr_train_loss=1.36726260, val_loss=1.60163021]\n","Validation Epoch [55/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.36it/s, val_loss=1.59261870]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55: Validation loss improved to 1.592619\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [56/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.85it/s, curr_train_loss=1.38210201, val_loss=1.59261870]\n","Validation Epoch [56/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.16it/s, val_loss=1.58109260]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56: Validation loss improved to 1.581093\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [57/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.90it/s, curr_train_loss=1.29482722, val_loss=1.58109260]\n","Validation Epoch [57/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.14it/s, val_loss=1.57366085]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57: Validation loss improved to 1.573661\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [58/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.85it/s, curr_train_loss=1.38660526, val_loss=1.57366085]\n","Validation Epoch [58/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.14it/s, val_loss=1.56296229]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58: Validation loss improved to 1.562962\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [59/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.52it/s, curr_train_loss=1.32784390, val_loss=1.56296229]\n","Validation Epoch [59/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.22it/s, val_loss=1.55411088]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59: Validation loss improved to 1.554111\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [60/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.22it/s, curr_train_loss=1.22935843, val_loss=1.55411088]\n","Validation Epoch [60/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.05it/s, val_loss=1.54702699]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60: Validation loss improved to 1.547027\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [61/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.72it/s, curr_train_loss=1.27033246, val_loss=1.54702699]\n","Validation Epoch [61/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.29it/s, val_loss=1.53801787]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61: Validation loss improved to 1.538018\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [62/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.27it/s, curr_train_loss=1.22449970, val_loss=1.53801787]\n","Validation Epoch [62/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.02it/s, val_loss=1.52900434]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62: Validation loss improved to 1.529004\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [63/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.47it/s, curr_train_loss=1.24388242, val_loss=1.52900434]\n","Validation Epoch [63/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.00it/s, val_loss=1.52022302]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63: Validation loss improved to 1.520223\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [64/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.79it/s, curr_train_loss=1.21458316, val_loss=1.52022302]\n","Validation Epoch [64/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.15it/s, val_loss=1.51086783]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64: Validation loss improved to 1.510868\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [65/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.47it/s, curr_train_loss=1.34109116, val_loss=1.51086783]\n","Validation Epoch [65/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.46it/s, val_loss=1.50036526]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65: Validation loss improved to 1.500365\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [66/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.67it/s, curr_train_loss=1.19377422, val_loss=1.50036526]\n","Validation Epoch [66/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.30it/s, val_loss=1.49039567]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66: Validation loss improved to 1.490396\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [67/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.18it/s, curr_train_loss=1.19901896, val_loss=1.49039567]\n","Validation Epoch [67/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.36it/s, val_loss=1.47956097]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67: Validation loss improved to 1.479561\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [68/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.68it/s, curr_train_loss=1.23214734, val_loss=1.47956097]\n","Validation Epoch [68/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.29it/s, val_loss=1.47256446]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68: Validation loss improved to 1.472564\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [69/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.51it/s, curr_train_loss=1.24930930, val_loss=1.47256446]\n","Validation Epoch [69/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.27it/s, val_loss=1.46509886]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69: Validation loss improved to 1.465099\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [70/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.74it/s, curr_train_loss=1.21053290, val_loss=1.46509886]\n","Validation Epoch [70/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.37it/s, val_loss=1.45837724]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70: Validation loss improved to 1.458377\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [71/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.73it/s, curr_train_loss=1.22206831, val_loss=1.45837724]\n","Validation Epoch [71/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.19it/s, val_loss=1.45117331]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71: Validation loss improved to 1.451173\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [72/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.89it/s, curr_train_loss=1.14936936, val_loss=1.45117331]\n","Validation Epoch [72/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.20it/s, val_loss=1.44416535]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72: Validation loss improved to 1.444165\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [73/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.60it/s, curr_train_loss=1.16729486, val_loss=1.44416535]\n","Validation Epoch [73/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.27it/s, val_loss=1.43854761]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73: Validation loss improved to 1.438548\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [74/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.61it/s, curr_train_loss=1.15913332, val_loss=1.43854761]\n","Validation Epoch [74/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.27it/s, val_loss=1.43083096]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74: Validation loss improved to 1.430831\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [75/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.87it/s, curr_train_loss=1.15995812, val_loss=1.43083096]\n","Validation Epoch [75/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.30it/s, val_loss=1.42449152]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75: Validation loss improved to 1.424492\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [76/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.77it/s, curr_train_loss=1.14483190, val_loss=1.42449152]\n","Validation Epoch [76/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.24it/s, val_loss=1.42094994]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76: Validation loss improved to 1.420950\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [77/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.63it/s, curr_train_loss=1.12103295, val_loss=1.42094994]\n","Validation Epoch [77/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.18it/s, val_loss=1.41388905]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77: Validation loss improved to 1.413889\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [78/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.73it/s, curr_train_loss=1.09894884, val_loss=1.41388905]\n","Validation Epoch [78/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.07it/s, val_loss=1.40856504]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78: Validation loss improved to 1.408565\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [79/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.74it/s, curr_train_loss=1.15708530, val_loss=1.40856504]\n","Validation Epoch [79/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.37it/s, val_loss=1.40620828]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79: Validation loss improved to 1.406208\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [80/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.82it/s, curr_train_loss=1.07123291, val_loss=1.40620828]\n","Validation Epoch [80/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.37it/s, val_loss=1.39978051]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80: Validation loss improved to 1.399781\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [81/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.67it/s, curr_train_loss=1.09348583, val_loss=1.39978051]\n","Validation Epoch [81/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.18it/s, val_loss=1.39104176]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81: Validation loss improved to 1.391042\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [82/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.92it/s, curr_train_loss=1.07679927, val_loss=1.39104176]\n","Validation Epoch [82/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.33it/s, val_loss=1.38555956]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82: Validation loss improved to 1.385560\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [83/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.73it/s, curr_train_loss=1.02121675, val_loss=1.38555956]\n","Validation Epoch [83/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.32it/s, val_loss=1.38098121]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83: Validation loss improved to 1.380981\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [84/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.82it/s, curr_train_loss=1.04952574, val_loss=1.38098121]\n","Validation Epoch [84/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.19it/s, val_loss=1.37686110]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84: Validation loss improved to 1.376861\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [85/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.61it/s, curr_train_loss=1.05434489, val_loss=1.37686110]\n","Validation Epoch [85/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.45it/s, val_loss=1.37486517]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85: Validation loss improved to 1.374865\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [86/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.75it/s, curr_train_loss=1.06139135, val_loss=1.37486517]\n","Validation Epoch [86/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.21it/s, val_loss=1.37277365]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86: Validation loss improved to 1.372774\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [87/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.92it/s, curr_train_loss=1.08803737, val_loss=1.37277365]\n","Validation Epoch [87/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.26it/s, val_loss=1.37054610]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87: Validation loss improved to 1.370546\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [88/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.60it/s, curr_train_loss=0.95145816, val_loss=1.37054610]\n","Validation Epoch [88/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.36it/s, val_loss=1.36845231]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88: Validation loss improved to 1.368452\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [89/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.85it/s, curr_train_loss=1.01477289, val_loss=1.36845231]\n","Validation Epoch [89/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.21it/s, val_loss=1.36426759]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89: Validation loss improved to 1.364268\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [90/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.77it/s, curr_train_loss=1.05950439, val_loss=1.36426759]\n","Validation Epoch [90/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.28it/s, val_loss=1.35836446]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90: Validation loss improved to 1.358364\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [91/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.10it/s, curr_train_loss=0.97439367, val_loss=1.35836446]\n","Validation Epoch [91/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.40it/s, val_loss=1.35101938]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91: Validation loss improved to 1.351019\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [92/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.80it/s, curr_train_loss=0.99798161, val_loss=1.35101938]\n","Validation Epoch [92/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.32it/s, val_loss=1.34797144]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92: Validation loss improved to 1.347971\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [93/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.89it/s, curr_train_loss=0.93674624, val_loss=1.34797144]\n","Validation Epoch [93/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.23it/s, val_loss=1.33975625]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93: Validation loss improved to 1.339756\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [94/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.81it/s, curr_train_loss=0.92102754, val_loss=1.33975625]\n","Validation Epoch [94/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.26it/s, val_loss=1.33128548]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94: Validation loss improved to 1.331285\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [95/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.51it/s, curr_train_loss=0.98914754, val_loss=1.33128548]\n","Validation Epoch [95/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.22it/s, val_loss=1.31667268]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95: Validation loss improved to 1.316673\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [96/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.73it/s, curr_train_loss=1.00557244, val_loss=1.31667268]\n","Validation Epoch [96/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.36it/s, val_loss=1.30453575]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96: Validation loss improved to 1.304536\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [97/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  5.86it/s, curr_train_loss=0.92113543, val_loss=1.30453575]\n","Validation Epoch [97/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.29it/s, val_loss=1.29569292]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97: Validation loss improved to 1.295693\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [98/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.94it/s, curr_train_loss=0.94335777, val_loss=1.29569292]\n","Validation Epoch [98/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.03it/s, val_loss=1.28991556]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98: Validation loss improved to 1.289916\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [99/100]: 100%|█████████████████████████████████████████| 1/1 [00:00<00:00,  4.74it/s, curr_train_loss=0.88351989, val_loss=1.28991556]\n","Validation Epoch [99/100]: 100%|███████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.26it/s, val_loss=1.28041196]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99: Validation loss improved to 1.280412\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [100/100]: 100%|████████████████████████████████████████| 1/1 [00:00<00:00,  5.23it/s, curr_train_loss=0.95637751, val_loss=1.28041196]\n","Validation Epoch [100/100]: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  9.31it/s, val_loss=1.27222157]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: Validation loss improved to 1.272222\n","Training completed. Best model restored.\n","Finished training!\n","How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\n","Training Acc: 94.0%\n","Validation Acc: 67.0%\n"]}],"source":["from exercise_code.models import Classifier\n","from exercise_code.models import Encoder\n","\n","# Create the encoder and the classifier.\n","encoder = Encoder(hparams).to(device)\n","classifier = Classifier(hparams, encoder).to(device)\n","\n","# Create a tensorboard logger.\n","# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n","# Also, in order to reset the logs, delete the logs folder MANUALLY.\n","\n","path = os.path.join('logs', 'cls_logs')\n","num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n","path = os.path.join(path, f'run_{num_of_runs + 1}')\n","\n","tb_logger = SummaryWriter(path)\n","\n","# Train the classifier.\n","labled_train_loader = torch.utils.data.DataLoader(train_100_dataset, batch_size=hparams['batch_size'], shuffle=True)\n","labled_val_loader = torch.utils.data.DataLoader(val_100_dataset, batch_size=hparams['batch_size'], shuffle=False)\n","\n","epochs = hparams.get('epochs', 10)\n","label_smoothing = hparams.get('label_smoothing', 0.0)\n","\n","# Use label smoothing if specified (helps with generalization)\n","if label_smoothing > 0:\n","    loss_func = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n","    print(f\"Using label smoothing: {label_smoothing}\")\n","else:\n","    loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n","\n","# Use more patience for early stopping with limited data\n","train_classifier(classifier, labled_train_loader, labled_val_loader, loss_func, tb_logger,\n","                epochs=epochs, name=\"Default\", early_stopping_patience=15, min_delta=1e-5)\n","\n","print(\"Finished training!\")\n","print(\"How did we do? Let's check the accuracy of the defaut classifier on the training and validation sets:\")\n","print(f\"Training Acc: {classifier.getAcc(labled_train_loader)[1] * 100}%\")\n","print(f\"Validation Acc: {classifier.getAcc(labled_val_loader)[1] * 100}%\")"]},{"cell_type":"markdown","metadata":{"id":"i16vmHZXMNkm"},"source":["# 3. Autoencoder\n","\n","With only a limited number of labeled images, it's challenging to achieve high performance. We have no money left to pay the student to create more labels, and labeling the data ourselves is out of question. A commonly used approach would be to apply data augmentation to maximize the potential of our limited labeled data, but here we provide another way to solve this problem: **transfer learning**.\n","\n","For each input, the autoencoder tries to reproduce the same image as an output. The difficulty behind this task is that the autoencoder has to go through a low dimensional bottleneck, which is called the **latent space**.\n","In other words, the autoencoder learns to represent all the input information in a low dimensional latent space - it learns to compress the input distribution. To train the autoencoder, we use the mean squared error loss, which calculates the discrepancy between the input pixels and the output pixels. The best part is that this loss function doesn't require any labels!\n","\n","By pretraining the autoencoder in this way on a large amount of unlabeled data, we can capture valuable latent representations of the input images. Then, we transfer the weights of the encoder to our classifier, enabling it to benefit from the knowledge learned during the unsupervised pretraining phase.\n","\n","<!-- In case the image does not show, uncomment the following:\n","![autoencoder](img/autoencoder.png)\n","-->\n","<img name=\"autoencoder\" src=\"https://i2dl.vc.in.tum.de/static/images/exercise_08/autoencoder.png\">\n","\n","After this, our encoder has learned to extract meaningful information from the inputs. We can then transfer its weights\n","to a classifier architecture and finetune it with our labeled data, i.e., instead of initializing our encoder randomly, we are re-using the weights of our trained encoder from our autoencoder network.\n","\n","<!-- In case the image does not show, uncomment the following:\n","![autoencoder_pretrained](img/pretrained.png)\n","-->\n","<img name=\"autoencoder_pretrained\" src=\"https://i2dl.vc.in.tum.de/static/images/exercise_08/pretrained.png\">\n","\n","\n","Before we can train our autoencoder, you have to initialize your `decoder` architecture. The simplest way is to mirror your encoder architecture, which ensures that the `latent space` output of our `encoder` is correctly transformed to our input shape.\n","\n","<div class=\"alert alert-info\">\n","    <h3>Task: Implement</h3>\n","    <p>Implement the <code>Decoder</code> class initialization in <code>exercise_code/models.py</code>.</p>\n","    <p>Implement <code>forward</code>, <code>set_optimizer</code>, <code>training_step</code> and <code>validation_step</code> of the <code>Autoencoder</code> in  <code>exercise_code/models.py</code>, following the pipeline we've shown you in train_classifier().</p>\n","    <p>Note the differences between the classification task and now the regression task!</p>\n","\n","\n","</div>\n","\n","## 3.2 Autoencoder Training\n","\n","Now, we can train the full autoencoder consisting of both en- and decoder.\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1767639608591,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"xqqdoLDgMNkm","scrolled":true},"outputs":[],"source":["from exercise_code.models import Autoencoder, Encoder, Decoder\n","\n","########################################################################\n","# TODO: Define your hyperparameters here!                              #\n","# Hint: use a large batch_size                                         #\n","########################################################################\n","\n","hparams = {\n","    # Model architecture - Enhanced with deeper networks and larger latent space\n","    'n_hidden_encoder': 512,      # First hidden layer size for encoder (increased)\n","    'n_hidden_encoder2': 256,     # Second hidden layer size for encoder (increased)\n","    'n_hidden_encoder3': 128,     # Third hidden layer size for encoder (increased)\n","    'latent_dim': 64,             # Latent space dimension (increased from 20 to 64)\n","    'n_hidden_classifier': 256,   # First hidden layer size for classifier\n","    'n_hidden_classifier2': 128,  # Second hidden layer size for classifier\n","    'n_hidden_classifier3': 64,   # Third hidden layer size for classifier\n","\n","    # Regularization\n","    'dropout_rate': 0.25,         # Dropout rate for encoder/decoder\n","    'classifier_dropout': 0.35,   # Dropout rate for classifier\n","    'weight_decay': 1e-4,         # Weight decay for L2 regularization (increased)\n","\n","    # Training parameters\n","    'learning_rate': 8e-4,        # Learning rate for optimizer\n","    'batch_size': 256,            # Batch size for training (larger for autoencoder)\n","    'epochs': 30,                 # Maximum epochs (early stopping will stop earlier) - longer for better pretraining\n","\n","    # Device\n","    'device': device\n","}\n","\n","########################################################################\n","#                           END OF YOUR CODE                           #\n","########################################################################\n","encoder_pretrained = Encoder(hparams).to(device)\n","decoder = Decoder(hparams).to(device)\n","autoencoder = Autoencoder(hparams, encoder_pretrained, decoder).to(device)"]},{"cell_type":"markdown","metadata":{"id":"uRuIIm8YMNkn"},"source":["Some tests to check whether we'll accept your model."]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":352,"status":"ok","timestamp":1767639608945,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"SoAaC-NqMNkn","outputId":"d6da9086-4dd3-4717-a665-f548bbbb2b6f","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["# Parameters: Your model has \u001b[92m1.142\u001b[0m mio. params.\n","Model accepted!\n"]}],"source":["from exercise_code.Util import printModelInfo, load_model\n","_ = printModelInfo(autoencoder)"]},{"cell_type":"markdown","metadata":{"id":"plQwnphtqggl"},"source":["After implementing the relevant functions - read the following code, and then run it.\n","Keep in mind that an epoch here will take much longer since\n","we are iterating through 5,8600 images instead of just 100.\n","\n","For speed, colab is indeed recommended."]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":60955,"status":"ok","timestamp":1767639669909,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"_uuzXMq6zjbb","outputId":"4ca20cc5-7360-4371-ea0d-6922c2877290","scrolled":true},"outputs":[{"output_type":"stream","name":"stderr","text":["Training Epoch [0/30]: 100%|███████████████████████████████████████████| 229/229 [00:02<00:00, 105.17it/s, train_loss=0.04829189, val_loss=0.00000000]\n","Validation Epoch [0/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 230.46it/s, val_loss=0.03276529]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Validation loss improved to 0.032765\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [1/30]: 100%|███████████████████████████████████████████| 229/229 [00:01<00:00, 129.23it/s, train_loss=0.03532553, val_loss=0.03276529]\n","Validation Epoch [1/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 239.04it/s, val_loss=0.03130586]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: Validation loss improved to 0.031306\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [2/30]: 100%|███████████████████████████████████████████| 229/229 [00:01<00:00, 128.57it/s, train_loss=0.03453246, val_loss=0.03130586]\n","Validation Epoch [2/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 240.90it/s, val_loss=0.03088668]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: Validation loss improved to 0.030887\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [3/30]: 100%|███████████████████████████████████████████| 229/229 [00:01<00:00, 128.24it/s, train_loss=0.03455880, val_loss=0.03088668]\n","Validation Epoch [3/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 230.04it/s, val_loss=0.03126890]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [4/30]: 100%|███████████████████████████████████████████| 229/229 [00:01<00:00, 129.22it/s, train_loss=0.03466809, val_loss=0.03126890]\n","Validation Epoch [4/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 241.81it/s, val_loss=0.03139972]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [5/30]: 100%|███████████████████████████████████████████| 229/229 [00:01<00:00, 122.87it/s, train_loss=0.03482720, val_loss=0.03139972]\n","Validation Epoch [5/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 157.45it/s, val_loss=0.03161485]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: No improvement. Patience: 3/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [6/30]: 100%|███████████████████████████████████████████| 229/229 [00:02<00:00, 100.60it/s, train_loss=0.03483361, val_loss=0.03161485]\n","Validation Epoch [6/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 187.87it/s, val_loss=0.03175118]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: No improvement. Patience: 4/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [7/30]: 100%|███████████████████████████████████████████| 229/229 [00:02<00:00, 110.07it/s, train_loss=0.03473470, val_loss=0.03175118]\n","Validation Epoch [7/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 250.12it/s, val_loss=0.03153568]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8: No improvement. Patience: 5/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [8/30]: 100%|███████████████████████████████████████████| 229/229 [00:01<00:00, 127.19it/s, train_loss=0.03462781, val_loss=0.03153568]\n","Validation Epoch [8/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 241.25it/s, val_loss=0.03112090]\n"]},{"output_type":"stream","name":"stdout","text":["Learning rate reduced from 0.000800 to 0.000400\n","Epoch 9: No improvement. Patience: 6/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [9/30]: 100%|███████████████████████████████████████████| 229/229 [00:01<00:00, 124.97it/s, train_loss=0.03384628, val_loss=0.03112090]\n","Validation Epoch [9/30]: 100%|████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 232.96it/s, val_loss=0.03009935]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Validation loss improved to 0.030099\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [10/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 125.79it/s, train_loss=0.03370127, val_loss=0.03009935]\n","Validation Epoch [10/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 224.51it/s, val_loss=0.03006694]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: Validation loss improved to 0.030067\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [11/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 128.09it/s, train_loss=0.03361762, val_loss=0.03006694]\n","Validation Epoch [11/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 221.72it/s, val_loss=0.02998520]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12: Validation loss improved to 0.029985\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [12/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 118.60it/s, train_loss=0.03359986, val_loss=0.02998520]\n","Validation Epoch [12/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 207.61it/s, val_loss=0.02983922]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13: Validation loss improved to 0.029839\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [13/30]: 100%|███████████████████████████████████████████| 229/229 [00:02<00:00, 98.61it/s, train_loss=0.03355172, val_loss=0.02983922]\n","Validation Epoch [13/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 141.51it/s, val_loss=0.02973668]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14: Validation loss improved to 0.029737\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [14/30]: 100%|██████████████████████████████████████████| 229/229 [00:02<00:00, 105.66it/s, train_loss=0.03345041, val_loss=0.02973668]\n","Validation Epoch [14/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 230.05it/s, val_loss=0.02964750]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15: Validation loss improved to 0.029647\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [15/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 127.68it/s, train_loss=0.03335214, val_loss=0.02964750]\n","Validation Epoch [15/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 243.22it/s, val_loss=0.02978802]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [16/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 126.34it/s, train_loss=0.03330160, val_loss=0.02978802]\n","Validation Epoch [16/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 237.52it/s, val_loss=0.02975828]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [17/30]: 100%|███████████████████████████████████████████| 229/229 [00:02<00:00, 93.59it/s, train_loss=0.03321819, val_loss=0.02975828]\n","Validation Epoch [17/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 219.68it/s, val_loss=0.02941728]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18: Validation loss improved to 0.029417\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [18/30]: 100%|██████████████████████████████████████████| 229/229 [00:02<00:00, 109.48it/s, train_loss=0.03320120, val_loss=0.02941728]\n","Validation Epoch [18/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 246.44it/s, val_loss=0.02941475]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19: Validation loss improved to 0.029415\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [19/30]: 100%|██████████████████████████████████████████| 229/229 [00:02<00:00, 100.66it/s, train_loss=0.03312808, val_loss=0.02941475]\n","Validation Epoch [19/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 207.11it/s, val_loss=0.02928733]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20: Validation loss improved to 0.029287\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [20/30]: 100%|███████████████████████████████████████████| 229/229 [00:02<00:00, 96.85it/s, train_loss=0.03307742, val_loss=0.02928733]\n","Validation Epoch [20/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 207.13it/s, val_loss=0.02949326]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [21/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 123.83it/s, train_loss=0.03306752, val_loss=0.02949326]\n","Validation Epoch [21/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 214.24it/s, val_loss=0.02914726]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22: Validation loss improved to 0.029147\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [22/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 128.43it/s, train_loss=0.03301073, val_loss=0.02914726]\n","Validation Epoch [22/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 251.91it/s, val_loss=0.02919067]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [23/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 122.40it/s, train_loss=0.03296078, val_loss=0.02919067]\n","Validation Epoch [23/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 229.96it/s, val_loss=0.02918303]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [24/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 123.49it/s, train_loss=0.03293198, val_loss=0.02918303]\n","Validation Epoch [24/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 248.94it/s, val_loss=0.02924845]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25: No improvement. Patience: 3/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [25/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 125.58it/s, train_loss=0.03288256, val_loss=0.02924845]\n","Validation Epoch [25/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 190.59it/s, val_loss=0.02906842]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26: Validation loss improved to 0.029068\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [26/30]: 100%|██████████████████████████████████████████| 229/229 [00:02<00:00, 101.61it/s, train_loss=0.03285672, val_loss=0.02906842]\n","Validation Epoch [26/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 212.29it/s, val_loss=0.02915549]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [27/30]: 100%|███████████████████████████████████████████| 229/229 [00:02<00:00, 91.04it/s, train_loss=0.03282053, val_loss=0.02915549]\n","Validation Epoch [27/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 179.17it/s, val_loss=0.02912244]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [28/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 123.12it/s, train_loss=0.03275284, val_loss=0.02912244]\n","Validation Epoch [28/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 236.48it/s, val_loss=0.02897897]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29: Validation loss improved to 0.028979\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [29/30]: 100%|██████████████████████████████████████████| 229/229 [00:01<00:00, 120.34it/s, train_loss=0.03274350, val_loss=0.02897897]\n","Validation Epoch [29/30]: 100%|███████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 215.40it/s, val_loss=0.02890060]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30: Validation loss improved to 0.028901\n","Training completed. Best model restored.\n","✅ Autoencoder training complete with extended epochs!\n","Finished training!\n"]}],"source":["encoder_pretrained = Encoder(hparams).to(device)\n","decoder = Decoder(hparams).to(device)\n","autoencoder = Autoencoder(hparams, encoder_pretrained, decoder).to(device)\n","\n","def train_model(model, train_loader, val_loader, loss_func, tb_logger, epochs=10, name='Autoencoder',\n","                early_stopping_patience=15, min_delta=1e-6):\n","    \"\"\"\n","    Train the autoencoder with early stopping and learning rate scheduling.\n","\n","    Args:\n","        early_stopping_patience: Number of epochs to wait before stopping if no improvement\n","        min_delta: Minimum change to qualify as an improvement\n","    \"\"\"\n","    optimizer = model.optimizer\n","\n","    # Enhanced learning rate scheduler - ReduceLROnPlateau adapts to validation loss\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6\n","    )\n","\n","    current_lr = optimizer.param_groups[0]['lr']\n","\n","    # Early stopping variables\n","    best_val_loss = float('inf')\n","    patience_counter = 0\n","    best_model_state = None\n","\n","    validation_loss = 0\n","    model = model.to(device)\n","    for epoch in range(epochs):\n","\n","        # Train\n","        training_loop = create_tqdm_bar(train_loader, desc=f'Training Epoch [{epoch}/{epochs}]')\n","        training_loss = 0\n","        for train_iteration, batch in training_loop:\n","\n","            loss = model.training_step(batch, loss_func) # You need to implement this function.\n","            training_loss += loss.item()\n","\n","            # Update the progress bar.\n","            training_loop.set_postfix(train_loss = \"{:.8f}\".format(training_loss / (train_iteration + 1)), val_loss = \"{:.8f}\".format(validation_loss))\n","\n","            # Update the tensorboard logger.\n","            tb_logger.add_scalar(f'{name}/train_loss', loss.item(), epoch * len(train_loader) + train_iteration)\n","\n","        # Validation\n","        val_loop = create_tqdm_bar(val_loader, desc=f'Validation Epoch [{epoch}/{epochs}]')\n","        validation_loss = 0\n","        with torch.no_grad():\n","            for val_iteration, batch in val_loop:\n","                loss = model.validation_step(batch, loss_func) # You need to implement this function.\n","                validation_loss += loss.item()\n","\n","                # Update the progress bar.\n","                val_loop.set_postfix(val_loss = \"{:.8f}\".format(validation_loss / (val_iteration + 1)))\n","\n","                # Update the tensorboard logger.\n","                tb_logger.add_scalar(f'{name}/val_loss', validation_loss / (val_iteration + 1), epoch * len(val_loader) + val_iteration)\n","        # This value is for the progress bar of the training loop.\n","        validation_loss /= len(val_loader)\n","\n","        # Learning rate scheduling based on validation loss\n","        old_lr = optimizer.param_groups[0]['lr']\n","        scheduler.step(validation_loss)\n","        new_lr = optimizer.param_groups[0]['lr']\n","        if old_lr != new_lr:\n","            print(f\"Learning rate reduced from {old_lr:.6f} to {new_lr:.6f}\")\n","\n","        # Early stopping logic\n","        if validation_loss < best_val_loss - min_delta:\n","            best_val_loss = validation_loss\n","            patience_counter = 0\n","            # Save best model state\n","            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n","            print(f\"Epoch {epoch+1}: Validation loss improved to {validation_loss:.6f}\")\n","        else:\n","            patience_counter += 1\n","            print(f\"Epoch {epoch+1}: No improvement. Patience: {patience_counter}/{early_stopping_patience}\")\n","\n","        # Early stopping check\n","        if patience_counter >= early_stopping_patience:\n","            print(f\"Early stopping triggered at epoch {epoch+1}. Restoring best model.\")\n","            model.load_state_dict(best_model_state)\n","            break\n","\n","    # Restore best model if early stopping didn't trigger\n","    if best_model_state is not None and patience_counter < early_stopping_patience:\n","        model.load_state_dict(best_model_state)\n","        print(\"Training completed. Best model restored.\")\n","\n","# Create a tensorboard logger.\n","# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n","# Also, in order to reset the logs, delete the logs folder MANUALLY.\n","\n","path = os.path.join('logs', 'ae_logs')\n","num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n","path = os.path.join(path, f'run_{num_of_runs + 1}')\n","tb_logger = SummaryWriter(path)\n","\n","# Train the classifier.\n","unlabled_train_loader = torch.utils.data.DataLoader(unlabeled_train, batch_size=hparams['batch_size'], shuffle=True)\n","unlabled_val_loader = torch.utils.data.DataLoader(unlabeled_val, batch_size=hparams['batch_size'], shuffle=False)\n","\n","epochs = hparams.get('epochs', 5)\n","loss_func = nn.MSELoss() # The loss function we use for regression (Could also be nn.L1Loss()).\n","# Train autoencoder with early stopping - train longer for better representations\n","# CRITICAL FIX: Autoencoder needs MUCH longer training!\n","# PROBLEM: Pretrained model got 51% vs 70% from scratch - pretraining was hurting!\n","# SOLUTION: Autoencoder needs 200+ epochs to learn good representations\n","# Train autoencoder with early stopping - train longer for better representations\n","train_model(autoencoder, unlabled_train_loader, unlabled_val_loader, loss_func, tb_logger,\n","           epochs=epochs, name='Autoencoder', early_stopping_patience=20, min_delta=1e-6)\n","\n","print(\"✅ Autoencoder training complete with extended epochs!\")\n","print(\"Finished training!\")"]},{"cell_type":"markdown","metadata":{"id":"vdgiYWy4MNkq"},"source":["Once trained, let's have a look at the reconstructed validation images (If you have not already looked at them in TensorBoard)."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1878,"status":"ok","timestamp":1767639671789,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"a991mKcyMNkq","outputId":"9520512e-7113-4f73-8b18-4c34f2e4efe6"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1600x1600 with 64 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["reconstructions = autoencoder.getReconstructions(unlabled_val_loader)\n","for i in range(64):\n","    plt.subplot(8,8,i+1)\n","    plt.axis('off')\n","    plt.imshow(reconstructions[i], cmap='gray', interpolation='none')\n","\n","plt.tight_layout()"]},{"cell_type":"markdown","metadata":{"id":"R2hrP5b1MNkr"},"source":["# 4. Transfer Learning\n","\n","## 4.1 The pretrained Classifier\n","\n","Now we initialize another classifier but this time with the pretrained encoder."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1767639671810,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"Z1RGYEocFzUj"},"outputs":[],"source":["from exercise_code.models import Classifier\n","from copy import deepcopy\n","\n","########################################################################\n","# TODO: Define your hyperparameters here!                             #\n","########################################################################\n","\n","hparams = {\n","    # Model architecture (should match encoder architecture)\n","    'n_hidden_encoder': 512,      # First hidden layer size for encoder\n","    'n_hidden_encoder2': 256,     # Second hidden layer size for encoder\n","    'n_hidden_encoder3': 128,     # Third hidden layer size for encoder\n","    'latent_dim': 64,             # Latent space dimension (must match autoencoder)\n","    'n_hidden_classifier': 256,   # First hidden layer size for classifier\n","    'n_hidden_classifier2': 128,  # Second hidden layer size for classifier\n","    'n_hidden_classifier3': 64,   # Third hidden layer size for classifier\n","\n","    # Regularization\n","    'dropout_rate': 0.25,         # Dropout rate for encoder/decoder\n","    'classifier_dropout': 0.35,   # Dropout rate for classifier\n","    'weight_decay': 1e-4,         # Weight decay for L2 regularization\n","    'label_smoothing': 0.1,       # Label smoothing for better generalization\n","\n","    # Training parameters - Progressive fine-tuning\n","    'learning_rate': 3e-4,         # Very low learning rate for fine-tuning (pretrained model)\n","    'encoder_lr': 1e-4,           # Much lower LR for pretrained encoder to preserve learned features\n","    'batch_size': 64,             # Batch size for training\n","    'epochs': 100,                # Maximum epochs (early stopping will stop earlier)\n","\n","    # Device\n","    'device': device\n","}\n","\n","########################################################################\n","#                           END OF YOUR CODE                           #\n","########################################################################\n","\n","encoder_pretrained_copy = deepcopy(encoder_pretrained)\n","classifier_pretrained = Classifier(hparams, encoder_pretrained_copy).to(device)"]},{"cell_type":"markdown","metadata":{"id":"R8FUtih6MNks"},"source":["Let's define another trainer that will utilize the pretrained classifier, allowing us to compare its performance with the classifier trained only on the labeled data. To achieve a reasonable result, you may need to optimize the parameters you defined earlier."]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52136,"status":"ok","timestamp":1767639723955,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"},"user_tz":-60},"id":"Mx_euorWMNks","outputId":"578d263a-d2a7-460e-c7e2-5da50a2391b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using label smoothing: 0.1\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [1/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.74it/s, curr_train_loss=2.37178802, val_loss=0.00000000]\n","Validation Epoch [1/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=2.31437898]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Validation loss improved to 2.314379\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [2/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=2.37995362, val_loss=2.31437898]\n","Validation Epoch [2/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=2.31971276]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [3/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=2.35961664, val_loss=2.31971276]\n","Validation Epoch [3/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.32327735]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [4/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=2.35185862, val_loss=2.32327735]\n","Validation Epoch [4/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.32542109]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: No improvement. Patience: 3/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [5/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=2.28564715, val_loss=2.32542109]\n","Validation Epoch [5/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.32689869]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: No improvement. Patience: 4/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [6/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.09it/s, curr_train_loss=2.20950460, val_loss=2.32689869]\n","Validation Epoch [6/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.32891250]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: No improvement. Patience: 5/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [7/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.99it/s, curr_train_loss=2.20271719, val_loss=2.32891250]\n","Validation Epoch [7/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.32922184]\n"]},{"output_type":"stream","name":"stdout","text":["Learning rate reduced from 0.000100 to 0.000050\n","Epoch 7: No improvement. Patience: 6/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [8/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.92it/s, curr_train_loss=2.20178115, val_loss=2.32922184]\n","Validation Epoch [8/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.12it/s, val_loss=2.32962275]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8: No improvement. Patience: 7/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [9/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.44it/s, curr_train_loss=2.23825550, val_loss=2.32962275]\n","Validation Epoch [9/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=2.32912505]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: No improvement. Patience: 8/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [10/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.13it/s, curr_train_loss=2.21844077, val_loss=2.32912505]\n","Validation Epoch [10/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=2.32907510]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: No improvement. Patience: 9/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [11/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.38it/s, curr_train_loss=2.23256278, val_loss=2.32907510]\n","Validation Epoch [11/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.16it/s, val_loss=2.32858646]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: No improvement. Patience: 10/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [12/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.96it/s, curr_train_loss=2.22537410, val_loss=2.32858646]\n","Validation Epoch [12/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.07it/s, val_loss=2.32650781]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12: No improvement. Patience: 11/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [13/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.41it/s, curr_train_loss=2.16012514, val_loss=2.32650781]\n","Validation Epoch [13/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=2.32503867]\n"]},{"output_type":"stream","name":"stdout","text":["Learning rate reduced from 0.000050 to 0.000025\n","Epoch 13: No improvement. Patience: 12/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [14/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=2.16721165, val_loss=2.32503867]\n","Validation Epoch [14/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.32336485]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14: No improvement. Patience: 13/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [15/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=2.12577415, val_loss=2.32336485]\n","Validation Epoch [15/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.32172251]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15: No improvement. Patience: 14/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [16/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.21it/s, curr_train_loss=2.06800365, val_loss=2.32172251]\n","Validation Epoch [16/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.31934047]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16: No improvement. Patience: 15/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [17/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.22it/s, curr_train_loss=2.18852639, val_loss=2.31934047]\n","Validation Epoch [17/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.31656516]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17: No improvement. Patience: 16/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [18/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.95it/s, curr_train_loss=2.08958936, val_loss=2.31656516]\n","Validation Epoch [18/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.31332016]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18: Validation loss improved to 2.313320\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [19/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=2.08911324, val_loss=2.31332016]\n","Validation Epoch [19/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.30960476]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19: Validation loss improved to 2.309605\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [20/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=2.10911417, val_loss=2.30960476]\n","Validation Epoch [20/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.30666387]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20: Validation loss improved to 2.306664\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [21/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.21it/s, curr_train_loss=2.15655649, val_loss=2.30666387]\n","Validation Epoch [21/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.30307043]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21: Validation loss improved to 2.303070\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [22/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=2.11466587, val_loss=2.30307043]\n","Validation Epoch [22/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.29800522]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22: Validation loss improved to 2.298005\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [23/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=2.07734644, val_loss=2.29800522]\n","Validation Epoch [23/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.29189634]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23: Validation loss improved to 2.291896\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [24/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=2.11786163, val_loss=2.29189634]\n","Validation Epoch [24/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.28709495]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24: Validation loss improved to 2.287095\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [25/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=2.04286301, val_loss=2.28709495]\n","Validation Epoch [25/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.28072488]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25: Validation loss improved to 2.280725\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [26/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=2.03811109, val_loss=2.28072488]\n","Validation Epoch [26/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.27366912]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26: Validation loss improved to 2.273669\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [27/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=2.09417009, val_loss=2.27366912]\n","Validation Epoch [27/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.26281488]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27: Validation loss improved to 2.262815\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [28/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.18it/s, curr_train_loss=2.09400058, val_loss=2.26281488]\n","Validation Epoch [28/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.25525129]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28: Validation loss improved to 2.255251\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [29/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=2.02536130, val_loss=2.25525129]\n","Validation Epoch [29/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.24575436]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29: Validation loss improved to 2.245754\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [30/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.85it/s, curr_train_loss=2.12484610, val_loss=2.24575436]\n","Validation Epoch [30/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.23700440]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30: Validation loss improved to 2.237004\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [31/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.21it/s, curr_train_loss=2.06509691, val_loss=2.23700440]\n","Validation Epoch [31/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=2.22653282]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31: Validation loss improved to 2.226533\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [32/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.13it/s, curr_train_loss=2.00446194, val_loss=2.22653282]\n","Validation Epoch [32/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.21613550]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32: Validation loss improved to 2.216136\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [33/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.92it/s, curr_train_loss=1.98207140, val_loss=2.21613550]\n","Validation Epoch [33/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.20363986]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33: Validation loss improved to 2.203640\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [34/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.34it/s, curr_train_loss=2.04607570, val_loss=2.20363986]\n","Validation Epoch [34/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=2.18928087]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34: Validation loss improved to 2.189281\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [35/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.39it/s, curr_train_loss=2.04313111, val_loss=2.18928087]\n","Validation Epoch [35/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.25it/s, val_loss=2.17709959]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35: Validation loss improved to 2.177100\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [36/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.17it/s, curr_train_loss=2.05993915, val_loss=2.17709959]\n","Validation Epoch [36/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.14it/s, val_loss=2.16434038]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36: Validation loss improved to 2.164340\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [37/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.92it/s, curr_train_loss=2.04268718, val_loss=2.16434038]\n","Validation Epoch [37/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=2.14789653]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37: Validation loss improved to 2.147897\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [38/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.14it/s, curr_train_loss=2.00231212, val_loss=2.14789653]\n","Validation Epoch [38/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.13390028]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38: Validation loss improved to 2.133900\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [39/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.16it/s, curr_train_loss=1.99581790, val_loss=2.13390028]\n","Validation Epoch [39/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.12208593]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39: Validation loss improved to 2.122086\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [40/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=2.10942483, val_loss=2.12208593]\n","Validation Epoch [40/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.10797119]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40: Validation loss improved to 2.107971\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [41/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=2.05913603, val_loss=2.10797119]\n","Validation Epoch [41/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=2.09383130]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41: Validation loss improved to 2.093831\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [42/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.13it/s, curr_train_loss=1.93889380, val_loss=2.09383130]\n","Validation Epoch [42/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.08571625]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42: Validation loss improved to 2.085716\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [43/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.07it/s, curr_train_loss=1.96273339, val_loss=2.08571625]\n","Validation Epoch [43/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.07441258]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43: Validation loss improved to 2.074413\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [44/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.22it/s, curr_train_loss=1.97878665, val_loss=2.07441258]\n","Validation Epoch [44/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.06852758]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44: Validation loss improved to 2.068528\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [45/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=1.97218037, val_loss=2.06852758]\n","Validation Epoch [45/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.05882859]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45: Validation loss improved to 2.058829\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [46/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=2.01103020, val_loss=2.05882859]\n","Validation Epoch [46/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.04649013]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46: Validation loss improved to 2.046490\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [47/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=1.95885968, val_loss=2.04649013]\n","Validation Epoch [47/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=2.03924513]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47: Validation loss improved to 2.039245\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [48/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.24it/s, curr_train_loss=1.91438979, val_loss=2.03924513]\n","Validation Epoch [48/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.03392357]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48: Validation loss improved to 2.033924\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [49/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.02it/s, curr_train_loss=1.98852324, val_loss=2.03392357]\n","Validation Epoch [49/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.02671510]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49: Validation loss improved to 2.026715\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [50/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=1.97518325, val_loss=2.02671510]\n","Validation Epoch [50/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.02295506]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50: Validation loss improved to 2.022955\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [51/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=2.08325303, val_loss=2.02295506]\n","Validation Epoch [51/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.01587212]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51: Validation loss improved to 2.015872\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [52/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.87it/s, curr_train_loss=1.93058848, val_loss=2.01587212]\n","Validation Epoch [52/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.00834376]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52: Validation loss improved to 2.008344\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [53/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=2.02351236, val_loss=2.00834376]\n","Validation Epoch [53/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=2.00316721]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53: Validation loss improved to 2.003167\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [54/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.90066063, val_loss=2.00316721]\n","Validation Epoch [54/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.99650973]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54: Validation loss improved to 1.996510\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [55/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.03it/s, curr_train_loss=1.89610267, val_loss=1.99650973]\n","Validation Epoch [55/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.99195421]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55: Validation loss improved to 1.991954\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [56/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=1.95619082, val_loss=1.99195421]\n","Validation Epoch [56/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.98996663]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56: Validation loss improved to 1.989967\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [57/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.64it/s, curr_train_loss=1.92445385, val_loss=1.98996663]\n","Validation Epoch [57/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.98851120]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57: Validation loss improved to 1.988511\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [58/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.50it/s, curr_train_loss=1.96347910, val_loss=1.98851120]\n","Validation Epoch [58/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=1.98344100]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58: Validation loss improved to 1.983441\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [59/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s, curr_train_loss=1.95636451, val_loss=1.98344100]\n","Validation Epoch [59/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.97937906]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59: Validation loss improved to 1.979379\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [60/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.39it/s, curr_train_loss=1.95565325, val_loss=1.97937906]\n","Validation Epoch [60/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.13it/s, val_loss=1.97524643]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60: Validation loss improved to 1.975246\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [61/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.95it/s, curr_train_loss=1.88163769, val_loss=1.97524643]\n","Validation Epoch [61/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.22it/s, val_loss=1.97171879]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61: Validation loss improved to 1.971719\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [62/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.07it/s, curr_train_loss=1.93396163, val_loss=1.97171879]\n","Validation Epoch [62/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.25it/s, val_loss=1.96684951]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62: Validation loss improved to 1.966850\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [63/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=1.86618805, val_loss=1.96684951]\n","Validation Epoch [63/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.96466380]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63: Validation loss improved to 1.964664\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [64/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.92848212, val_loss=1.96466380]\n","Validation Epoch [64/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.96029156]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64: Validation loss improved to 1.960292\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [65/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.92it/s, curr_train_loss=1.86688709, val_loss=1.96029156]\n","Validation Epoch [65/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=1.95754266]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65: Validation loss improved to 1.957543\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [66/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=1.92478198, val_loss=1.95754266]\n","Validation Epoch [66/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.95242453]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66: Validation loss improved to 1.952425\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [67/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.98431134, val_loss=1.95242453]\n","Validation Epoch [67/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.94969881]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67: Validation loss improved to 1.949699\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [68/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.22it/s, curr_train_loss=1.98264664, val_loss=1.94969881]\n","Validation Epoch [68/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.94622672]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68: Validation loss improved to 1.946227\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [69/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=1.83198148, val_loss=1.94622672]\n","Validation Epoch [69/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.94155622]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69: Validation loss improved to 1.941556\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [70/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.82026017, val_loss=1.94155622]\n","Validation Epoch [70/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.94341534]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [71/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.07it/s, curr_train_loss=1.88672930, val_loss=1.94341534]\n","Validation Epoch [71/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.94147837]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71: Validation loss improved to 1.941478\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [72/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.19it/s, curr_train_loss=1.91857719, val_loss=1.94147837]\n","Validation Epoch [72/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.93700087]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72: Validation loss improved to 1.937001\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [73/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.55it/s, curr_train_loss=1.85458720, val_loss=1.93700087]\n","Validation Epoch [73/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.93554115]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73: Validation loss improved to 1.935541\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [74/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.07it/s, curr_train_loss=1.87690687, val_loss=1.93554115]\n","Validation Epoch [74/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.93061441]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74: Validation loss improved to 1.930614\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [75/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.65it/s, curr_train_loss=1.88739586, val_loss=1.93061441]\n","Validation Epoch [75/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.92298496]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75: Validation loss improved to 1.922985\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [76/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.07it/s, curr_train_loss=1.79366612, val_loss=1.92298496]\n","Validation Epoch [76/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.91906142]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76: Validation loss improved to 1.919061\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [77/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.70it/s, curr_train_loss=1.84373349, val_loss=1.91906142]\n","Validation Epoch [77/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.91851979]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77: Validation loss improved to 1.918520\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [78/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.20it/s, curr_train_loss=1.88806355, val_loss=1.91851979]\n","Validation Epoch [78/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.91528362]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78: Validation loss improved to 1.915284\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [79/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.84271324, val_loss=1.91528362]\n","Validation Epoch [79/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.91446680]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79: Validation loss improved to 1.914467\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [80/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.98it/s, curr_train_loss=1.85765845, val_loss=1.91446680]\n","Validation Epoch [80/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.91061854]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80: Validation loss improved to 1.910619\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [81/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.23it/s, curr_train_loss=1.81524950, val_loss=1.91061854]\n","Validation Epoch [81/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.90114021]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81: Validation loss improved to 1.901140\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [82/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.58it/s, curr_train_loss=1.79763454, val_loss=1.90114021]\n","Validation Epoch [82/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=1.89606792]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82: Validation loss improved to 1.896068\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [83/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.90it/s, curr_train_loss=1.86203969, val_loss=1.89606792]\n","Validation Epoch [83/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=1.89693743]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [84/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.31it/s, curr_train_loss=1.80315870, val_loss=1.89693743]\n","Validation Epoch [84/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.89549953]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84: Validation loss improved to 1.895500\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [85/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.74it/s, curr_train_loss=1.79142445, val_loss=1.89549953]\n","Validation Epoch [85/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.14it/s, val_loss=1.89411658]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85: Validation loss improved to 1.894117\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [86/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.74it/s, curr_train_loss=1.84748316, val_loss=1.89411658]\n","Validation Epoch [86/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=1.89263535]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86: Validation loss improved to 1.892635\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [87/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.73it/s, curr_train_loss=1.85726142, val_loss=1.89263535]\n","Validation Epoch [87/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.88922471]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87: Validation loss improved to 1.889225\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [88/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.82352597, val_loss=1.88922471]\n","Validation Epoch [88/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.88811314]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88: Validation loss improved to 1.888113\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [89/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.46it/s, curr_train_loss=1.81525767, val_loss=1.88811314]\n","Validation Epoch [89/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.88262081]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89: Validation loss improved to 1.882621\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [90/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=1.80261815, val_loss=1.88262081]\n","Validation Epoch [90/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.87657684]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90: Validation loss improved to 1.876577\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [91/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=1.79788327, val_loss=1.87657684]\n","Validation Epoch [91/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=1.87325168]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91: Validation loss improved to 1.873252\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [92/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=1.80041504, val_loss=1.87325168]\n","Validation Epoch [92/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.87109858]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92: Validation loss improved to 1.871099\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [93/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.98it/s, curr_train_loss=1.78390455, val_loss=1.87109858]\n","Validation Epoch [93/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.86398369]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93: Validation loss improved to 1.863984\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [94/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=1.76094729, val_loss=1.86398369]\n","Validation Epoch [94/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.86583203]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [95/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.75it/s, curr_train_loss=1.69945383, val_loss=1.86583203]\n","Validation Epoch [95/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.86717260]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [96/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.78100568, val_loss=1.86717260]\n","Validation Epoch [96/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.86612189]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96: No improvement. Patience: 3/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [97/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.57it/s, curr_train_loss=1.83355343, val_loss=1.86612189]\n","Validation Epoch [97/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.86025327]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97: Validation loss improved to 1.860253\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [98/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.75648379, val_loss=1.86025327]\n","Validation Epoch [98/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.85894150]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98: Validation loss improved to 1.858941\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [99/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.82it/s, curr_train_loss=1.76084679, val_loss=1.85894150]\n","Validation Epoch [99/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.85678476]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99: Validation loss improved to 1.856785\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [100/100]: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=1.73532748, val_loss=1.85678476]\n","Validation Epoch [100/100]: 100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.85063064]"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: Validation loss improved to 1.850631\n","Training completed. Best model restored.\n","Finished training!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["\n","# Create a tensorboard logger.\n","# NOTE: In order to see the logs, run the following command in the terminal: tensorboard --logdir=./\n","# Also, in order to reset the logs, delete the logs folder MANUALLY.\n","# Pay attention that if you run this cell mutltiple times, the pretrained_encoder\n","# is not reset, and will keep training from where it stopped. Thus, it could overfit.\n","\n","path = os.path.join('logs', 'pretrained_cls_logs')\n","num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n","path = os.path.join(path, f'run_{num_of_runs + 1}')\n","tb_logger = SummaryWriter(path)\n","\n","batch_size = hparams.get('batch_size', 16)\n","labled_train_loader = torch.utils.data.DataLoader(train_100_dataset, batch_size=batch_size, shuffle=True)\n","labled_val_loader = torch.utils.data.DataLoader(val_100_dataset, batch_size=batch_size, shuffle=False)\n","\n","epochs = hparams.get('epochs', 20)\n","label_smoothing = hparams.get('label_smoothing', 0.0)\n","\n","# Use label smoothing if specified (helps with generalization)\n","if label_smoothing > 0:\n","    loss_func = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n","    print(f\"Using label smoothing: {label_smoothing}\")\n","else:\n","    loss_func = nn.CrossEntropyLoss() # The loss function we use for classification.\n","\n","# Use more patience for early stopping with limited data\n","train_classifier(classifier_pretrained, labled_train_loader, labled_val_loader, loss_func, tb_logger,\n","                epochs=epochs, name='Pretrained', early_stopping_patience=20, min_delta=1e-5)\n","\n","print(\"Finished training!\")"]},{"cell_type":"markdown","metadata":{"id":"yH8uJRMxv0m9"},"source":["## 4.2 Ensemble Training for Maximum Performance\n","\n","To achieve 98%+ accuracy, we'll train an ensemble of models with different random seeds and use Test-Time Augmentation (TTA). This is one of the most effective techniques for pushing accuracy to the limit.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c10AdcgCv0m9","outputId":"03d88c5b-2b07-4410-a5e6-f7e45ece4190","executionInfo":{"status":"ok","timestamp":1767639997727,"user_tz":-60,"elapsed":273770,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["============================================================\n","TRAINING ENSEMBLE FOR MAXIMUM ACCURACY\n","============================================================\n","This will train multiple models - it will take time but gives best results!\n","============================================================\n","\n","============================================================\n","Training Ensemble Model 1/5\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [1/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=2.39750373, val_loss=0.00000000]\n","Validation Epoch [1/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.30075467]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Validation loss improved to 2.300755\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [2/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=2.49915254, val_loss=2.30075467]\n","Validation Epoch [2/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.29731417]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: Validation loss improved to 2.297314\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [3/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.02it/s, curr_train_loss=2.40697765, val_loss=2.29731417]\n","Validation Epoch [3/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.29445648]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: Validation loss improved to 2.294456\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [4/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=2.34125447, val_loss=2.29445648]\n","Validation Epoch [4/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=2.29205322]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: Validation loss improved to 2.292053\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [5/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.26it/s, curr_train_loss=2.25835121, val_loss=2.29205322]\n","Validation Epoch [5/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.29006481]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: Validation loss improved to 2.290065\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [6/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.12it/s, curr_train_loss=2.34222794, val_loss=2.29006481]\n","Validation Epoch [6/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.28870916]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: Validation loss improved to 2.288709\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [7/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.50it/s, curr_train_loss=2.30691767, val_loss=2.28870916]\n","Validation Epoch [7/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=2.28701746]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: Validation loss improved to 2.287017\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [8/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.05it/s, curr_train_loss=2.23980069, val_loss=2.28701746]\n","Validation Epoch [8/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=2.28571022]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8: Validation loss improved to 2.285710\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [9/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.45it/s, curr_train_loss=2.21763885, val_loss=2.28571022]\n","Validation Epoch [9/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.28459585]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: Validation loss improved to 2.284596\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [10/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.16it/s, curr_train_loss=2.19086409, val_loss=2.28459585]\n","Validation Epoch [10/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=2.28331542]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Validation loss improved to 2.283315\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [11/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=2.17642260, val_loss=2.28331542]\n","Validation Epoch [11/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.28231359]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: Validation loss improved to 2.282314\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [12/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.02it/s, curr_train_loss=2.16244352, val_loss=2.28231359]\n","Validation Epoch [12/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.51it/s, val_loss=2.28146565]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12: Validation loss improved to 2.281466\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [13/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=2.15657449, val_loss=2.28146565]\n","Validation Epoch [13/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.27980292]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13: Validation loss improved to 2.279803\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [14/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=2.11586225, val_loss=2.27980292]\n","Validation Epoch [14/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.27748549]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14: Validation loss improved to 2.277485\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [15/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=2.08197093, val_loss=2.27748549]\n","Validation Epoch [15/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.27477360]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15: Validation loss improved to 2.274774\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [16/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.81it/s, curr_train_loss=2.12836456, val_loss=2.27477360]\n","Validation Epoch [16/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=2.27143502]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16: Validation loss improved to 2.271435\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [17/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=2.06822479, val_loss=2.27143502]\n","Validation Epoch [17/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.26774037]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17: Validation loss improved to 2.267740\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [18/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=2.05604243, val_loss=2.26774037]\n","Validation Epoch [18/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.26366246]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18: Validation loss improved to 2.263662\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [19/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.14it/s, curr_train_loss=1.99949753, val_loss=2.26366246]\n","Validation Epoch [19/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=2.25947607]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19: Validation loss improved to 2.259476\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [20/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.22it/s, curr_train_loss=1.98890507, val_loss=2.25947607]\n","Validation Epoch [20/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.25408900]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20: Validation loss improved to 2.254089\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [21/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.99309897, val_loss=2.25408900]\n","Validation Epoch [21/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=2.24755442]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21: Validation loss improved to 2.247554\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [22/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.13it/s, curr_train_loss=2.01021212, val_loss=2.24755442]\n","Validation Epoch [22/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.24061036]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22: Validation loss improved to 2.240610\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [23/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=2.02777040, val_loss=2.24061036]\n","Validation Epoch [23/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.23318350]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23: Validation loss improved to 2.233184\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [24/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.28it/s, curr_train_loss=1.93735445, val_loss=2.23318350]\n","Validation Epoch [24/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.22325289]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24: Validation loss improved to 2.223253\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [25/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.13it/s, curr_train_loss=1.99807382, val_loss=2.22325289]\n","Validation Epoch [25/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.21355081]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25: Validation loss improved to 2.213551\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [26/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.21it/s, curr_train_loss=1.88599825, val_loss=2.21355081]\n","Validation Epoch [26/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.20255184]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26: Validation loss improved to 2.202552\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [27/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=1.95267737, val_loss=2.20255184]\n","Validation Epoch [27/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.18971837]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27: Validation loss improved to 2.189718\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [28/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.17it/s, curr_train_loss=1.85510957, val_loss=2.18971837]\n","Validation Epoch [28/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.17512012]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28: Validation loss improved to 2.175120\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [29/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.47it/s, curr_train_loss=1.88752657, val_loss=2.17512012]\n","Validation Epoch [29/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=2.15948236]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29: Validation loss improved to 2.159482\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [30/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.45it/s, curr_train_loss=1.88426179, val_loss=2.15948236]\n","Validation Epoch [30/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.25it/s, val_loss=2.14031601]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30: Validation loss improved to 2.140316\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [31/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.31it/s, curr_train_loss=1.89162600, val_loss=2.14031601]\n","Validation Epoch [31/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.24it/s, val_loss=2.11955404]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31: Validation loss improved to 2.119554\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [32/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.29it/s, curr_train_loss=1.83573759, val_loss=2.11955404]\n","Validation Epoch [32/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=2.09375596]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32: Validation loss improved to 2.093756\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [33/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.05it/s, curr_train_loss=1.79977798, val_loss=2.09375596]\n","Validation Epoch [33/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.06771266]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33: Validation loss improved to 2.067713\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [34/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.84278512, val_loss=2.06771266]\n","Validation Epoch [34/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.03791642]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34: Validation loss improved to 2.037916\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [35/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.75574988, val_loss=2.03791642]\n","Validation Epoch [35/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.00770915]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35: Validation loss improved to 2.007709\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [36/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.02it/s, curr_train_loss=1.73632127, val_loss=2.00770915]\n","Validation Epoch [36/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.97655046]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36: Validation loss improved to 1.976550\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [37/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.86400664, val_loss=1.97655046]\n","Validation Epoch [37/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.94362205]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37: Validation loss improved to 1.943622\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [38/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.46it/s, curr_train_loss=1.70760465, val_loss=1.94362205]\n","Validation Epoch [38/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.91446471]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38: Validation loss improved to 1.914465\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [39/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.21it/s, curr_train_loss=1.73805350, val_loss=1.91446471]\n","Validation Epoch [39/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.88566214]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39: Validation loss improved to 1.885662\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [40/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.18it/s, curr_train_loss=1.68802279, val_loss=1.88566214]\n","Validation Epoch [40/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=1.85432452]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40: Validation loss improved to 1.854325\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [41/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.98it/s, curr_train_loss=1.71275675, val_loss=1.85432452]\n","Validation Epoch [41/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.82529646]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41: Validation loss improved to 1.825296\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [42/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.83it/s, curr_train_loss=1.70028257, val_loss=1.82529646]\n","Validation Epoch [42/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.79743224]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42: Validation loss improved to 1.797432\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [43/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.98it/s, curr_train_loss=1.66719788, val_loss=1.79743224]\n","Validation Epoch [43/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.77615196]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43: Validation loss improved to 1.776152\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [44/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.79it/s, curr_train_loss=1.69520718, val_loss=1.77615196]\n","Validation Epoch [44/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.75636709]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44: Validation loss improved to 1.756367\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [45/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=1.73091400, val_loss=1.75636709]\n","Validation Epoch [45/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.73868918]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45: Validation loss improved to 1.738689\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [46/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.63743508, val_loss=1.73868918]\n","Validation Epoch [46/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.72415233]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46: Validation loss improved to 1.724152\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [47/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=1.72314769, val_loss=1.72415233]\n","Validation Epoch [47/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=1.70360708]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47: Validation loss improved to 1.703607\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [48/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.76it/s, curr_train_loss=1.59071451, val_loss=1.70360708]\n","Validation Epoch [48/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.69021070]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48: Validation loss improved to 1.690211\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [49/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.94it/s, curr_train_loss=1.57972199, val_loss=1.69021070]\n","Validation Epoch [49/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.67789638]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49: Validation loss improved to 1.677896\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [50/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.64it/s, curr_train_loss=1.57116747, val_loss=1.67789638]\n","Validation Epoch [50/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.66953230]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50: Validation loss improved to 1.669532\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [51/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.60606438, val_loss=1.66953230]\n","Validation Epoch [51/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.29it/s, val_loss=1.65539271]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51: Validation loss improved to 1.655393\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [52/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.92it/s, curr_train_loss=1.61223710, val_loss=1.65539271]\n","Validation Epoch [52/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.64371562]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52: Validation loss improved to 1.643716\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [53/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.07it/s, curr_train_loss=1.57034421, val_loss=1.64371562]\n","Validation Epoch [53/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.63709575]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53: Validation loss improved to 1.637096\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [54/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.35it/s, curr_train_loss=1.56682926, val_loss=1.63709575]\n","Validation Epoch [54/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=1.62747693]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54: Validation loss improved to 1.627477\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [55/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.27it/s, curr_train_loss=1.51729929, val_loss=1.62747693]\n","Validation Epoch [55/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.18it/s, val_loss=1.61441064]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55: Validation loss improved to 1.614411\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [56/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.16it/s, curr_train_loss=1.46768582, val_loss=1.61441064]\n","Validation Epoch [56/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.22it/s, val_loss=1.61251259]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56: Validation loss improved to 1.612513\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [57/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.91it/s, curr_train_loss=1.51617670, val_loss=1.61251259]\n","Validation Epoch [57/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.60537314]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57: Validation loss improved to 1.605373\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [58/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=1.51453996, val_loss=1.60537314]\n","Validation Epoch [58/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.59987420]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58: Validation loss improved to 1.599874\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [59/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.13it/s, curr_train_loss=1.51643413, val_loss=1.59987420]\n","Validation Epoch [59/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.59517193]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59: Validation loss improved to 1.595172\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [60/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.51455271, val_loss=1.59517193]\n","Validation Epoch [60/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.58594507]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60: Validation loss improved to 1.585945\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [61/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.24it/s, curr_train_loss=1.47257423, val_loss=1.58594507]\n","Validation Epoch [61/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.57663584]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61: Validation loss improved to 1.576636\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [62/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.75it/s, curr_train_loss=1.44042963, val_loss=1.57663584]\n","Validation Epoch [62/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.57439429]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62: Validation loss improved to 1.574394\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [63/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.94it/s, curr_train_loss=1.49957013, val_loss=1.57439429]\n","Validation Epoch [63/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.56384748]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63: Validation loss improved to 1.563847\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [64/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=1.43513334, val_loss=1.56384748]\n","Validation Epoch [64/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.55940223]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64: Validation loss improved to 1.559402\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [65/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.18it/s, curr_train_loss=1.42442775, val_loss=1.55940223]\n","Validation Epoch [65/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.55661076]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65: Validation loss improved to 1.556611\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [66/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.63it/s, curr_train_loss=1.42534345, val_loss=1.55661076]\n","Validation Epoch [66/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.55191314]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66: Validation loss improved to 1.551913\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [67/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=1.49868459, val_loss=1.55191314]\n","Validation Epoch [67/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.54170847]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67: Validation loss improved to 1.541708\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [68/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.70it/s, curr_train_loss=1.45141441, val_loss=1.54170847]\n","Validation Epoch [68/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.53454781]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68: Validation loss improved to 1.534548\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [69/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.25it/s, curr_train_loss=1.33431262, val_loss=1.53454781]\n","Validation Epoch [69/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.52447468]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69: Validation loss improved to 1.524475\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [70/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.92it/s, curr_train_loss=1.40649003, val_loss=1.52447468]\n","Validation Epoch [70/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.51314312]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70: Validation loss improved to 1.513143\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [71/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.07it/s, curr_train_loss=1.36049503, val_loss=1.51314312]\n","Validation Epoch [71/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.50959003]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71: Validation loss improved to 1.509590\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [72/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.92it/s, curr_train_loss=1.31105030, val_loss=1.50959003]\n","Validation Epoch [72/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.50123918]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72: Validation loss improved to 1.501239\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [73/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=1.38128477, val_loss=1.50123918]\n","Validation Epoch [73/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.50053054]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73: Validation loss improved to 1.500531\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [74/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.44023120, val_loss=1.50053054]\n","Validation Epoch [74/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.48681247]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74: Validation loss improved to 1.486812\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [75/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.35622019, val_loss=1.48681247]\n","Validation Epoch [75/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.48052484]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75: Validation loss improved to 1.480525\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [76/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.02it/s, curr_train_loss=1.30436170, val_loss=1.48052484]\n","Validation Epoch [76/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.47669226]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76: Validation loss improved to 1.476692\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [77/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.26it/s, curr_train_loss=1.36015326, val_loss=1.47669226]\n","Validation Epoch [77/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.21it/s, val_loss=1.47330445]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77: Validation loss improved to 1.473304\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [78/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.99it/s, curr_train_loss=1.26287276, val_loss=1.47330445]\n","Validation Epoch [78/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=1.47280079]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78: Validation loss improved to 1.472801\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [79/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.60it/s, curr_train_loss=1.29418367, val_loss=1.47280079]\n","Validation Epoch [79/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.46780133]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79: Validation loss improved to 1.467801\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [80/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.08it/s, curr_train_loss=1.25492173, val_loss=1.46780133]\n","Validation Epoch [80/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.25it/s, val_loss=1.46861446]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [81/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.85it/s, curr_train_loss=1.35157627, val_loss=1.46861446]\n","Validation Epoch [81/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.46649575]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81: Validation loss improved to 1.466496\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [82/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.14it/s, curr_train_loss=1.37827146, val_loss=1.46649575]\n","Validation Epoch [82/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.46037751]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82: Validation loss improved to 1.460378\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [83/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.03it/s, curr_train_loss=1.36924607, val_loss=1.46037751]\n","Validation Epoch [83/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.45794094]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83: Validation loss improved to 1.457941\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [84/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=1.25849515, val_loss=1.45794094]\n","Validation Epoch [84/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.45238954]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84: Validation loss improved to 1.452390\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [85/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.95it/s, curr_train_loss=1.18939292, val_loss=1.45238954]\n","Validation Epoch [85/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.45194942]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85: Validation loss improved to 1.451949\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [86/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=1.25053990, val_loss=1.45194942]\n","Validation Epoch [86/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=1.44919294]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86: Validation loss improved to 1.449193\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [87/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=1.19853646, val_loss=1.44919294]\n","Validation Epoch [87/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.44755536]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87: Validation loss improved to 1.447555\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [88/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=1.25770593, val_loss=1.44755536]\n","Validation Epoch [88/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.44357777]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88: Validation loss improved to 1.443578\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [89/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=1.24124837, val_loss=1.44357777]\n","Validation Epoch [89/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.43574381]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89: Validation loss improved to 1.435744\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [90/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.67it/s, curr_train_loss=1.22435051, val_loss=1.43574381]\n","Validation Epoch [90/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.43042088]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90: Validation loss improved to 1.430421\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [91/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.25917655, val_loss=1.43042088]\n","Validation Epoch [91/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.43070960]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [92/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.60it/s, curr_train_loss=1.22607636, val_loss=1.43070960]\n","Validation Epoch [92/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.42882127]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92: Validation loss improved to 1.428821\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [93/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.09it/s, curr_train_loss=1.22735822, val_loss=1.42882127]\n","Validation Epoch [93/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.52it/s, val_loss=1.42729783]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93: Validation loss improved to 1.427298\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [94/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=1.20631504, val_loss=1.42729783]\n","Validation Epoch [94/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.42042810]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94: Validation loss improved to 1.420428\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [95/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.02it/s, curr_train_loss=1.18284750, val_loss=1.42042810]\n","Validation Epoch [95/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.41881382]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95: Validation loss improved to 1.418814\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [96/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.95it/s, curr_train_loss=1.15085745, val_loss=1.41881382]\n","Validation Epoch [96/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=1.41304141]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96: Validation loss improved to 1.413041\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [97/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.02it/s, curr_train_loss=1.09217930, val_loss=1.41304141]\n","Validation Epoch [97/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.40421247]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97: Validation loss improved to 1.404212\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [98/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.11089247, val_loss=1.40421247]\n","Validation Epoch [98/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.40268201]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98: Validation loss improved to 1.402682\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [99/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.03it/s, curr_train_loss=1.10938722, val_loss=1.40268201]\n","Validation Epoch [99/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.39600629]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99: Validation loss improved to 1.396006\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [100/100]: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=1.14903599, val_loss=1.39600629]\n","Validation Epoch [100/100]: 100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.39148158]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: Validation loss improved to 1.391482\n","Training completed. Best model restored.\n","Model 1 Validation Accuracy: 63.00%\n","\n","============================================================\n","Training Ensemble Model 2/5\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [1/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.12it/s, curr_train_loss=2.37103701, val_loss=0.00000000]\n","Validation Epoch [1/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=2.30306804]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Validation loss improved to 2.303068\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [2/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  5.99it/s, curr_train_loss=2.35938120, val_loss=2.30306804]\n","Validation Epoch [2/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.20it/s, val_loss=2.30193853]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: Validation loss improved to 2.301939\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [3/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s, curr_train_loss=2.32471395, val_loss=2.30193853]\n","Validation Epoch [3/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.30195940]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [4/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s, curr_train_loss=2.32137215, val_loss=2.30195940]\n","Validation Epoch [4/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.12it/s, val_loss=2.30187023]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: Validation loss improved to 2.301870\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [5/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  5.96it/s, curr_train_loss=2.24883139, val_loss=2.30187023]\n","Validation Epoch [5/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.30206430]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [6/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=2.30204332, val_loss=2.30206430]\n","Validation Epoch [6/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.30215919]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [7/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=2.22028506, val_loss=2.30215919]\n","Validation Epoch [7/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.30191445]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: No improvement. Patience: 3/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [8/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.18it/s, curr_train_loss=2.26840413, val_loss=2.30191445]\n","Validation Epoch [8/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.30190408]\n"]},{"output_type":"stream","name":"stdout","text":["Learning rate reduced from 0.000100 to 0.000050\n","Epoch 8: No improvement. Patience: 4/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [9/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.03it/s, curr_train_loss=2.21034455, val_loss=2.30190408]\n","Validation Epoch [9/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.30214524]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: No improvement. Patience: 5/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [10/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=2.21018577, val_loss=2.30214524]\n","Validation Epoch [10/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=2.30229723]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: No improvement. Patience: 6/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [11/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.13it/s, curr_train_loss=2.18356788, val_loss=2.30229723]\n","Validation Epoch [11/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.30240202]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: No improvement. Patience: 7/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [12/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.86it/s, curr_train_loss=2.12445509, val_loss=2.30240202]\n","Validation Epoch [12/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.30245245]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12: No improvement. Patience: 8/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [13/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.95it/s, curr_train_loss=2.18684459, val_loss=2.30245245]\n","Validation Epoch [13/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.30196905]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13: No improvement. Patience: 9/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [14/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=2.15304828, val_loss=2.30196905]\n","Validation Epoch [14/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.30241859]\n"]},{"output_type":"stream","name":"stdout","text":["Learning rate reduced from 0.000050 to 0.000025\n","Epoch 14: No improvement. Patience: 10/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [15/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=2.20439804, val_loss=2.30241859]\n","Validation Epoch [15/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=2.30142558]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15: Validation loss improved to 2.301426\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [16/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.16it/s, curr_train_loss=2.15733039, val_loss=2.30142558]\n","Validation Epoch [16/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.30057418]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16: Validation loss improved to 2.300574\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [17/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.07it/s, curr_train_loss=2.14380157, val_loss=2.30057418]\n","Validation Epoch [17/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.30005789]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17: Validation loss improved to 2.300058\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [18/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.17it/s, curr_train_loss=2.19450235, val_loss=2.30005789]\n","Validation Epoch [18/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=2.29827940]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18: Validation loss improved to 2.298279\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [19/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.89it/s, curr_train_loss=2.13734210, val_loss=2.29827940]\n","Validation Epoch [19/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.29579329]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19: Validation loss improved to 2.295793\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [20/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.32it/s, curr_train_loss=2.07977247, val_loss=2.29579329]\n","Validation Epoch [20/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.29410625]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20: Validation loss improved to 2.294106\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [21/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=2.07253456, val_loss=2.29410625]\n","Validation Epoch [21/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=2.29204464]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21: Validation loss improved to 2.292045\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [22/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.03it/s, curr_train_loss=2.10194898, val_loss=2.29204464]\n","Validation Epoch [22/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.28953052]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22: Validation loss improved to 2.289531\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [23/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.85it/s, curr_train_loss=2.12871766, val_loss=2.28953052]\n","Validation Epoch [23/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.28606153]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23: Validation loss improved to 2.286062\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [24/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=2.10537755, val_loss=2.28606153]\n","Validation Epoch [24/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.28289866]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24: Validation loss improved to 2.282899\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [25/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.41it/s, curr_train_loss=2.08579493, val_loss=2.28289866]\n","Validation Epoch [25/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.11it/s, val_loss=2.27881753]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25: Validation loss improved to 2.278818\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [26/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.23it/s, curr_train_loss=2.07427478, val_loss=2.27881753]\n","Validation Epoch [26/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=2.27401996]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26: Validation loss improved to 2.274020\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [27/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.12it/s, curr_train_loss=2.01789731, val_loss=2.27401996]\n","Validation Epoch [27/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=2.26711118]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27: Validation loss improved to 2.267111\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [28/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.55it/s, curr_train_loss=2.11962378, val_loss=2.26711118]\n","Validation Epoch [28/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=2.26119757]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28: Validation loss improved to 2.261198\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [29/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.12it/s, curr_train_loss=2.11697602, val_loss=2.26119757]\n","Validation Epoch [29/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=2.25559676]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29: Validation loss improved to 2.255597\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [30/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.06it/s, curr_train_loss=2.02774960, val_loss=2.25559676]\n","Validation Epoch [30/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.24629581]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30: Validation loss improved to 2.246296\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [31/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=2.12095332, val_loss=2.24629581]\n","Validation Epoch [31/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.23821616]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31: Validation loss improved to 2.238216\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [32/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=2.03822148, val_loss=2.23821616]\n","Validation Epoch [32/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.22870779]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32: Validation loss improved to 2.228708\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [33/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.94it/s, curr_train_loss=2.09312022, val_loss=2.22870779]\n","Validation Epoch [33/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.21889806]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33: Validation loss improved to 2.218898\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [34/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=2.06774819, val_loss=2.21889806]\n","Validation Epoch [34/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.20834041]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34: Validation loss improved to 2.208340\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [35/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.98772514, val_loss=2.20834041]\n","Validation Epoch [35/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=2.19724393]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35: Validation loss improved to 2.197244\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [36/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.98026276, val_loss=2.19724393]\n","Validation Epoch [36/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.18447268]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36: Validation loss improved to 2.184473\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [37/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=2.05093479, val_loss=2.18447268]\n","Validation Epoch [37/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.17453921]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37: Validation loss improved to 2.174539\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [38/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=1.99797606, val_loss=2.17453921]\n","Validation Epoch [38/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.16192913]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38: Validation loss improved to 2.161929\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [39/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.09it/s, curr_train_loss=2.04545355, val_loss=2.16192913]\n","Validation Epoch [39/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.15075135]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39: Validation loss improved to 2.150751\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [40/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.29it/s, curr_train_loss=2.08024323, val_loss=2.15075135]\n","Validation Epoch [40/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.13955307]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40: Validation loss improved to 2.139553\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [41/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=2.01968348, val_loss=2.13955307]\n","Validation Epoch [41/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.12946582]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41: Validation loss improved to 2.129466\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [42/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.97it/s, curr_train_loss=1.98738009, val_loss=2.12946582]\n","Validation Epoch [42/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.11832786]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42: Validation loss improved to 2.118328\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [43/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=2.03567815, val_loss=2.11832786]\n","Validation Epoch [43/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.11112750]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43: Validation loss improved to 2.111127\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [44/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=2.04002225, val_loss=2.11112750]\n","Validation Epoch [44/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.10295248]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44: Validation loss improved to 2.102952\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [45/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.70it/s, curr_train_loss=1.99042606, val_loss=2.10295248]\n","Validation Epoch [45/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=2.09736371]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45: Validation loss improved to 2.097364\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [46/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.19it/s, curr_train_loss=2.08057535, val_loss=2.09736371]\n","Validation Epoch [46/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.09304929]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46: Validation loss improved to 2.093049\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [47/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.18it/s, curr_train_loss=2.01484275, val_loss=2.09304929]\n","Validation Epoch [47/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.08705139]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47: Validation loss improved to 2.087051\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [48/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.17it/s, curr_train_loss=2.03187340, val_loss=2.08705139]\n","Validation Epoch [48/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.08227122]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48: Validation loss improved to 2.082271\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [49/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.14it/s, curr_train_loss=2.04423392, val_loss=2.08227122]\n","Validation Epoch [49/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.22it/s, val_loss=2.07774937]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49: Validation loss improved to 2.077749\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [50/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s, curr_train_loss=1.98454845, val_loss=2.07774937]\n","Validation Epoch [50/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=2.07449400]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50: Validation loss improved to 2.074494\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [51/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.13it/s, curr_train_loss=2.01826781, val_loss=2.07449400]\n","Validation Epoch [51/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.21it/s, val_loss=2.06895173]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51: Validation loss improved to 2.068952\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [52/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.14it/s, curr_train_loss=2.00901580, val_loss=2.06895173]\n","Validation Epoch [52/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.20it/s, val_loss=2.06473899]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52: Validation loss improved to 2.064739\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [53/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.50it/s, curr_train_loss=1.97079432, val_loss=2.06473899]\n","Validation Epoch [53/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.22it/s, val_loss=2.06121695]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53: Validation loss improved to 2.061217\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [54/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.35it/s, curr_train_loss=1.96810174, val_loss=2.06121695]\n","Validation Epoch [54/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.05521929]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54: Validation loss improved to 2.055219\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [55/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.94649768, val_loss=2.05521929]\n","Validation Epoch [55/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.05332994]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55: Validation loss improved to 2.053330\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [56/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=2.01117820, val_loss=2.05332994]\n","Validation Epoch [56/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.04557025]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56: Validation loss improved to 2.045570\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [57/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=1.96058464, val_loss=2.04557025]\n","Validation Epoch [57/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=2.04426384]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57: Validation loss improved to 2.044264\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [58/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=1.96676946, val_loss=2.04426384]\n","Validation Epoch [58/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.04141140]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58: Validation loss improved to 2.041411\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [59/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=1.98879302, val_loss=2.04141140]\n","Validation Epoch [59/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.03656566]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59: Validation loss improved to 2.036566\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [60/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.90318018, val_loss=2.03656566]\n","Validation Epoch [60/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=2.03323328]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60: Validation loss improved to 2.033233\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [61/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.10it/s, curr_train_loss=1.98081988, val_loss=2.03323328]\n","Validation Epoch [61/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.03247333]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61: Validation loss improved to 2.032473\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [62/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=1.88594091, val_loss=2.03247333]\n","Validation Epoch [62/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.02763140]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62: Validation loss improved to 2.027631\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [63/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.91927356, val_loss=2.02763140]\n","Validation Epoch [63/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.02492964]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63: Validation loss improved to 2.024930\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [64/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.09it/s, curr_train_loss=1.98188806, val_loss=2.02492964]\n","Validation Epoch [64/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.02424848]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64: Validation loss improved to 2.024248\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [65/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=1.90030247, val_loss=2.02424848]\n","Validation Epoch [65/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.02214038]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65: Validation loss improved to 2.022140\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [66/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.09it/s, curr_train_loss=1.96831071, val_loss=2.02214038]\n","Validation Epoch [66/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.02243090]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [67/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=1.95747280, val_loss=2.02243090]\n","Validation Epoch [67/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.02231532]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [68/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.03it/s, curr_train_loss=2.02428645, val_loss=2.02231532]\n","Validation Epoch [68/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.01852667]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68: Validation loss improved to 2.018527\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [69/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.91312420, val_loss=2.01852667]\n","Validation Epoch [69/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.01658928]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69: Validation loss improved to 2.016589\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [70/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=1.88381004, val_loss=2.01658928]\n","Validation Epoch [70/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.01422024]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70: Validation loss improved to 2.014220\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [71/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.03it/s, curr_train_loss=1.95721471, val_loss=2.01422024]\n","Validation Epoch [71/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.01087236]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71: Validation loss improved to 2.010872\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [72/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.95495874, val_loss=2.01087236]\n","Validation Epoch [72/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.00710309]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72: Validation loss improved to 2.007103\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [73/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.21it/s, curr_train_loss=1.90335548, val_loss=2.00710309]\n","Validation Epoch [73/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.29it/s, val_loss=2.00564986]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73: Validation loss improved to 2.005650\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [74/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.30it/s, curr_train_loss=1.90978938, val_loss=2.00564986]\n","Validation Epoch [74/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=2.00832301]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [75/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.21it/s, curr_train_loss=1.95203060, val_loss=2.00832301]\n","Validation Epoch [75/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.00975347]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [76/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.28it/s, curr_train_loss=1.91542298, val_loss=2.00975347]\n","Validation Epoch [76/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=2.00562596]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76: Validation loss improved to 2.005626\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [77/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.02it/s, curr_train_loss=1.87046129, val_loss=2.00562596]\n","Validation Epoch [77/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.14it/s, val_loss=2.00378656]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77: Validation loss improved to 2.003787\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [78/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.52it/s, curr_train_loss=1.84484565, val_loss=2.00378656]\n","Validation Epoch [78/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=2.00327969]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78: Validation loss improved to 2.003280\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [79/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.89183295, val_loss=2.00327969]\n","Validation Epoch [79/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=2.00183064]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79: Validation loss improved to 2.001831\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [80/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=1.91470486, val_loss=2.00183064]\n","Validation Epoch [80/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.00040287]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80: Validation loss improved to 2.000403\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [81/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=1.86123347, val_loss=2.00040287]\n","Validation Epoch [81/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.99458450]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81: Validation loss improved to 1.994585\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [82/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.97it/s, curr_train_loss=1.93164384, val_loss=1.99458450]\n","Validation Epoch [82/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=1.99237508]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82: Validation loss improved to 1.992375\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [83/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.15it/s, curr_train_loss=1.86805397, val_loss=1.99237508]\n","Validation Epoch [83/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.99008620]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83: Validation loss improved to 1.990086\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [84/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.93144113, val_loss=1.99008620]\n","Validation Epoch [84/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.98829073]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84: Validation loss improved to 1.988291\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [85/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.02it/s, curr_train_loss=1.78795922, val_loss=1.98829073]\n","Validation Epoch [85/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.98751891]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85: Validation loss improved to 1.987519\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [86/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.89it/s, curr_train_loss=1.90520930, val_loss=1.98751891]\n","Validation Epoch [86/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.98597866]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86: Validation loss improved to 1.985979\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [87/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.99it/s, curr_train_loss=1.82276011, val_loss=1.98597866]\n","Validation Epoch [87/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.98376131]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87: Validation loss improved to 1.983761\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [88/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.87it/s, curr_train_loss=1.87815934, val_loss=1.98376131]\n","Validation Epoch [88/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.51it/s, val_loss=1.98279834]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88: Validation loss improved to 1.982798\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [89/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.85382718, val_loss=1.98279834]\n","Validation Epoch [89/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.98205823]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89: Validation loss improved to 1.982058\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [90/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.95it/s, curr_train_loss=1.81573677, val_loss=1.98205823]\n","Validation Epoch [90/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=1.97871125]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90: Validation loss improved to 1.978711\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [91/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.82630140, val_loss=1.97871125]\n","Validation Epoch [91/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.97948241]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [92/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.99it/s, curr_train_loss=1.82927698, val_loss=1.97948241]\n","Validation Epoch [92/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=1.97534859]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92: Validation loss improved to 1.975349\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [93/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.31it/s, curr_train_loss=1.80791229, val_loss=1.97534859]\n","Validation Epoch [93/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.29it/s, val_loss=1.97745323]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [94/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=1.83118933, val_loss=1.97745323]\n","Validation Epoch [94/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.97393620]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94: Validation loss improved to 1.973936\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [95/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.80861729, val_loss=1.97393620]\n","Validation Epoch [95/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.96863234]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95: Validation loss improved to 1.968632\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [96/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.80001003, val_loss=1.96863234]\n","Validation Epoch [96/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.96755636]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96: Validation loss improved to 1.967556\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [97/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.98it/s, curr_train_loss=1.77598011, val_loss=1.96755636]\n","Validation Epoch [97/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.96698380]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97: Validation loss improved to 1.966984\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [98/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.83it/s, curr_train_loss=1.78948271, val_loss=1.96698380]\n","Validation Epoch [98/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.96204424]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98: Validation loss improved to 1.962044\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [99/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.44it/s, curr_train_loss=1.79965669, val_loss=1.96204424]\n","Validation Epoch [99/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.21it/s, val_loss=1.96045011]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99: Validation loss improved to 1.960450\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [100/100]: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s, curr_train_loss=1.85268056, val_loss=1.96045011]\n","Validation Epoch [100/100]: 100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.95704472]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: Validation loss improved to 1.957045\n","Training completed. Best model restored.\n","Model 2 Validation Accuracy: 46.00%\n","\n","============================================================\n","Training Ensemble Model 3/5\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [1/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  5.90it/s, curr_train_loss=2.42389369, val_loss=0.00000000]\n","Validation Epoch [1/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.30652082]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Validation loss improved to 2.306521\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [2/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.12it/s, curr_train_loss=2.34819221, val_loss=2.30652082]\n","Validation Epoch [2/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.30733228]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [3/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.97it/s, curr_train_loss=2.35369825, val_loss=2.30733228]\n","Validation Epoch [3/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.30652595]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [4/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=2.34207594, val_loss=2.30652595]\n","Validation Epoch [4/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.30606270]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: Validation loss improved to 2.306063\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [5/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.98it/s, curr_train_loss=2.34147382, val_loss=2.30606270]\n","Validation Epoch [5/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.30509090]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: Validation loss improved to 2.305091\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [6/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.17it/s, curr_train_loss=2.30909252, val_loss=2.30509090]\n","Validation Epoch [6/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.30409777]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: Validation loss improved to 2.304098\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [7/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.64it/s, curr_train_loss=2.35760498, val_loss=2.30409777]\n","Validation Epoch [7/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.30293822]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: Validation loss improved to 2.302938\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [8/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  7.03it/s, curr_train_loss=2.27125120, val_loss=2.30293822]\n","Validation Epoch [8/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.30126154]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8: Validation loss improved to 2.301262\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [9/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.40it/s, curr_train_loss=2.15658808, val_loss=2.30126154]\n","Validation Epoch [9/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.30021358]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: Validation loss improved to 2.300214\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [10/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=2.20203054, val_loss=2.30021358]\n","Validation Epoch [10/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.29776967]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Validation loss improved to 2.297770\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [11/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.61it/s, curr_train_loss=2.20515335, val_loss=2.29776967]\n","Validation Epoch [11/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.29562008]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: Validation loss improved to 2.295620\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [12/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.81it/s, curr_train_loss=2.13766074, val_loss=2.29562008]\n","Validation Epoch [12/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.29387593]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12: Validation loss improved to 2.293876\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [13/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.94it/s, curr_train_loss=2.12047005, val_loss=2.29387593]\n","Validation Epoch [13/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.29156852]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13: Validation loss improved to 2.291569\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [14/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=2.11672986, val_loss=2.29156852]\n","Validation Epoch [14/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.28802836]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14: Validation loss improved to 2.288028\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [15/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.04it/s, curr_train_loss=2.06072581, val_loss=2.28802836]\n","Validation Epoch [15/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.28523302]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15: Validation loss improved to 2.285233\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [16/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.89it/s, curr_train_loss=2.10633850, val_loss=2.28523302]\n","Validation Epoch [16/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.28212166]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16: Validation loss improved to 2.282122\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [17/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.65it/s, curr_train_loss=2.04143679, val_loss=2.28212166]\n","Validation Epoch [17/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.27675605]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17: Validation loss improved to 2.276756\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [18/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=2.09962380, val_loss=2.27675605]\n","Validation Epoch [18/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.27146375]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18: Validation loss improved to 2.271464\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [19/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.52it/s, curr_train_loss=2.13005376, val_loss=2.27146375]\n","Validation Epoch [19/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.26545691]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19: Validation loss improved to 2.265457\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [20/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=2.01857913, val_loss=2.26545691]\n","Validation Epoch [20/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.25767839]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20: Validation loss improved to 2.257678\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [21/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.52it/s, curr_train_loss=2.03607798, val_loss=2.25767839]\n","Validation Epoch [21/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=2.24955630]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21: Validation loss improved to 2.249556\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [22/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.08it/s, curr_train_loss=1.99396390, val_loss=2.24955630]\n","Validation Epoch [22/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.29it/s, val_loss=2.24188924]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22: Validation loss improved to 2.241889\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [23/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.16it/s, curr_train_loss=2.01577109, val_loss=2.24188924]\n","Validation Epoch [23/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=2.23161721]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23: Validation loss improved to 2.231617\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [24/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.01it/s, curr_train_loss=1.95847350, val_loss=2.23161721]\n","Validation Epoch [24/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.22286117]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24: Validation loss improved to 2.222861\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [25/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.14it/s, curr_train_loss=1.88249570, val_loss=2.22286117]\n","Validation Epoch [25/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=2.21121073]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25: Validation loss improved to 2.211211\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [26/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.94it/s, curr_train_loss=1.91844684, val_loss=2.21121073]\n","Validation Epoch [26/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=2.19740534]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26: Validation loss improved to 2.197405\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [27/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.85it/s, curr_train_loss=1.90112174, val_loss=2.19740534]\n","Validation Epoch [27/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.18187058]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27: Validation loss improved to 2.181871\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [28/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=1.95907426, val_loss=2.18187058]\n","Validation Epoch [28/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.16632295]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28: Validation loss improved to 2.166323\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [29/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=1.83266819, val_loss=2.16632295]\n","Validation Epoch [29/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.14858174]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29: Validation loss improved to 2.148582\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [30/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=1.81455809, val_loss=2.14858174]\n","Validation Epoch [30/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.12999976]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30: Validation loss improved to 2.130000\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [31/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.99it/s, curr_train_loss=1.85280162, val_loss=2.12999976]\n","Validation Epoch [31/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.11299872]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31: Validation loss improved to 2.112999\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [32/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.90924418, val_loss=2.11299872]\n","Validation Epoch [32/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.09154117]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32: Validation loss improved to 2.091541\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [33/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.86it/s, curr_train_loss=1.77845687, val_loss=2.09154117]\n","Validation Epoch [33/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.06711638]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33: Validation loss improved to 2.067116\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [34/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=1.75240177, val_loss=2.06711638]\n","Validation Epoch [34/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.04053956]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34: Validation loss improved to 2.040540\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [35/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.92it/s, curr_train_loss=1.80826139, val_loss=2.04053956]\n","Validation Epoch [35/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.01646137]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35: Validation loss improved to 2.016461\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [36/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.74it/s, curr_train_loss=1.85196793, val_loss=2.01646137]\n","Validation Epoch [36/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.99035692]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36: Validation loss improved to 1.990357\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [37/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.99it/s, curr_train_loss=1.71461594, val_loss=1.99035692]\n","Validation Epoch [37/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.96615797]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37: Validation loss improved to 1.966158\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [38/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=1.80446672, val_loss=1.96615797]\n","Validation Epoch [38/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.94111359]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38: Validation loss improved to 1.941114\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [39/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=1.72502637, val_loss=1.94111359]\n","Validation Epoch [39/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.91781127]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39: Validation loss improved to 1.917811\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [40/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.21it/s, curr_train_loss=1.71443552, val_loss=1.91781127]\n","Validation Epoch [40/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.89577997]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40: Validation loss improved to 1.895780\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [41/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=1.71134096, val_loss=1.89577997]\n","Validation Epoch [41/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.87557435]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41: Validation loss improved to 1.875574\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [42/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.66709524, val_loss=1.87557435]\n","Validation Epoch [42/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.85909641]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42: Validation loss improved to 1.859096\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [43/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.07it/s, curr_train_loss=1.67803520, val_loss=1.85909641]\n","Validation Epoch [43/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.83661425]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43: Validation loss improved to 1.836614\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [44/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.63189948, val_loss=1.83661425]\n","Validation Epoch [44/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.52it/s, val_loss=1.81985039]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44: Validation loss improved to 1.819850\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [45/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.94it/s, curr_train_loss=1.72518820, val_loss=1.81985039]\n","Validation Epoch [45/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.80284011]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45: Validation loss improved to 1.802840\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [46/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.76it/s, curr_train_loss=1.64227462, val_loss=1.80284011]\n","Validation Epoch [46/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.79303890]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46: Validation loss improved to 1.793039\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [47/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.75it/s, curr_train_loss=1.64252526, val_loss=1.79303890]\n","Validation Epoch [47/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.77781379]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47: Validation loss improved to 1.777814\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [48/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.22it/s, curr_train_loss=1.68367326, val_loss=1.77781379]\n","Validation Epoch [48/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.76508123]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48: Validation loss improved to 1.765081\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [49/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.22it/s, curr_train_loss=1.57227468, val_loss=1.76508123]\n","Validation Epoch [49/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.12it/s, val_loss=1.75344652]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49: Validation loss improved to 1.753447\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [50/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.66it/s, curr_train_loss=1.56098306, val_loss=1.75344652]\n","Validation Epoch [50/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.74258029]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50: Validation loss improved to 1.742580\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [51/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.12it/s, curr_train_loss=1.46797532, val_loss=1.74258029]\n","Validation Epoch [51/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.73427653]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51: Validation loss improved to 1.734277\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [52/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=1.50518513, val_loss=1.73427653]\n","Validation Epoch [52/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.72784644]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52: Validation loss improved to 1.727846\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [53/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.51916641, val_loss=1.72784644]\n","Validation Epoch [53/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.71511340]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53: Validation loss improved to 1.715113\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [54/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.72it/s, curr_train_loss=1.53412378, val_loss=1.71511340]\n","Validation Epoch [54/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=1.70456171]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54: Validation loss improved to 1.704562\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [55/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.11it/s, curr_train_loss=1.52950424, val_loss=1.70456171]\n","Validation Epoch [55/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.69301325]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55: Validation loss improved to 1.693013\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [56/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.65it/s, curr_train_loss=1.43098778, val_loss=1.69301325]\n","Validation Epoch [56/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.68688476]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56: Validation loss improved to 1.686885\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [57/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.55it/s, curr_train_loss=1.51142764, val_loss=1.68688476]\n","Validation Epoch [57/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.67673248]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57: Validation loss improved to 1.676732\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [58/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.63it/s, curr_train_loss=1.51210773, val_loss=1.67673248]\n","Validation Epoch [58/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.67207491]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58: Validation loss improved to 1.672075\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [59/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.56909758, val_loss=1.67207491]\n","Validation Epoch [59/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.65889841]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59: Validation loss improved to 1.658898\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [60/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.91it/s, curr_train_loss=1.44466645, val_loss=1.65889841]\n","Validation Epoch [60/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.65541929]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60: Validation loss improved to 1.655419\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [61/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.45569283, val_loss=1.65541929]\n","Validation Epoch [61/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.64443970]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61: Validation loss improved to 1.644440\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [62/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=1.40095615, val_loss=1.64443970]\n","Validation Epoch [62/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.63697654]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62: Validation loss improved to 1.636977\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [63/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=1.42562187, val_loss=1.63697654]\n","Validation Epoch [63/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.62768441]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63: Validation loss improved to 1.627684\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [64/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.39177006, val_loss=1.62768441]\n","Validation Epoch [64/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.62063259]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64: Validation loss improved to 1.620633\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [65/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.46227193, val_loss=1.62063259]\n","Validation Epoch [65/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=1.61444402]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65: Validation loss improved to 1.614444\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [66/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.38658100, val_loss=1.61444402]\n","Validation Epoch [66/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.61010563]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66: Validation loss improved to 1.610106\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [67/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.75it/s, curr_train_loss=1.30432975, val_loss=1.61010563]\n","Validation Epoch [67/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.60296822]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67: Validation loss improved to 1.602968\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [68/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.35873377, val_loss=1.60296822]\n","Validation Epoch [68/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.59483123]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68: Validation loss improved to 1.594831\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [69/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=1.40223539, val_loss=1.59483123]\n","Validation Epoch [69/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.58926773]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69: Validation loss improved to 1.589268\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [70/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.06it/s, curr_train_loss=1.30299485, val_loss=1.58926773]\n","Validation Epoch [70/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=1.58489454]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70: Validation loss improved to 1.584895\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [71/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.28it/s, curr_train_loss=1.31929088, val_loss=1.58489454]\n","Validation Epoch [71/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.57541817]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71: Validation loss improved to 1.575418\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [72/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.66it/s, curr_train_loss=1.35540980, val_loss=1.57541817]\n","Validation Epoch [72/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.56661916]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72: Validation loss improved to 1.566619\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [73/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.29it/s, curr_train_loss=1.31345695, val_loss=1.56661916]\n","Validation Epoch [73/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.15it/s, val_loss=1.55681932]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73: Validation loss improved to 1.556819\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [74/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.65it/s, curr_train_loss=1.33836317, val_loss=1.55681932]\n","Validation Epoch [74/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.54968691]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74: Validation loss improved to 1.549687\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [75/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.28620470, val_loss=1.54968691]\n","Validation Epoch [75/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.54292643]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75: Validation loss improved to 1.542926\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [76/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.95it/s, curr_train_loss=1.31683987, val_loss=1.54292643]\n","Validation Epoch [76/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.53450090]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76: Validation loss improved to 1.534501\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [77/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.81it/s, curr_train_loss=1.32205939, val_loss=1.53450090]\n","Validation Epoch [77/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.19it/s, val_loss=1.52615929]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77: Validation loss improved to 1.526159\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [78/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.97it/s, curr_train_loss=1.40182912, val_loss=1.52615929]\n","Validation Epoch [78/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.52341640]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78: Validation loss improved to 1.523416\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [79/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s, curr_train_loss=1.28675538, val_loss=1.52341640]\n","Validation Epoch [79/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.51923203]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79: Validation loss improved to 1.519232\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [80/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.88it/s, curr_train_loss=1.31810135, val_loss=1.51923203]\n","Validation Epoch [80/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.51409799]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80: Validation loss improved to 1.514098\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [81/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.85it/s, curr_train_loss=1.26206225, val_loss=1.51409799]\n","Validation Epoch [81/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.50551718]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81: Validation loss improved to 1.505517\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [82/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.62it/s, curr_train_loss=1.26388174, val_loss=1.50551718]\n","Validation Epoch [82/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=1.49818003]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82: Validation loss improved to 1.498180\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [83/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.86it/s, curr_train_loss=1.38734007, val_loss=1.49818003]\n","Validation Epoch [83/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=1.49441552]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83: Validation loss improved to 1.494416\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [84/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.00it/s, curr_train_loss=1.20410246, val_loss=1.49441552]\n","Validation Epoch [84/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.48593450]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84: Validation loss improved to 1.485934\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [85/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s, curr_train_loss=1.15603268, val_loss=1.48593450]\n","Validation Epoch [85/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.47940832]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85: Validation loss improved to 1.479408\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [86/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.74it/s, curr_train_loss=1.17961532, val_loss=1.47940832]\n","Validation Epoch [86/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.46811277]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86: Validation loss improved to 1.468113\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [87/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.94it/s, curr_train_loss=1.14244062, val_loss=1.46811277]\n","Validation Epoch [87/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.17it/s, val_loss=1.45883602]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87: Validation loss improved to 1.458836\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [88/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.85it/s, curr_train_loss=1.20393580, val_loss=1.45883602]\n","Validation Epoch [88/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.45208108]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88: Validation loss improved to 1.452081\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [89/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.89it/s, curr_train_loss=1.21761060, val_loss=1.45208108]\n","Validation Epoch [89/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=1.45124096]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89: Validation loss improved to 1.451241\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [90/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.82it/s, curr_train_loss=1.18482715, val_loss=1.45124096]\n","Validation Epoch [90/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.44621783]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90: Validation loss improved to 1.446218\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [91/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s, curr_train_loss=1.22604740, val_loss=1.44621783]\n","Validation Epoch [91/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=1.44070238]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91: Validation loss improved to 1.440702\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [92/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.13899082, val_loss=1.44070238]\n","Validation Epoch [92/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.43833202]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92: Validation loss improved to 1.438332\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [93/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.19228119, val_loss=1.43833202]\n","Validation Epoch [93/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=1.43132037]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93: Validation loss improved to 1.431320\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [94/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.05it/s, curr_train_loss=1.14834154, val_loss=1.43132037]\n","Validation Epoch [94/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.42842793]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94: Validation loss improved to 1.428428\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [95/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.23it/s, curr_train_loss=1.20357424, val_loss=1.42842793]\n","Validation Epoch [95/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.11it/s, val_loss=1.42190152]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95: Validation loss improved to 1.421902\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [96/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.88it/s, curr_train_loss=1.21393430, val_loss=1.42190152]\n","Validation Epoch [96/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.42459381]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [97/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.27it/s, curr_train_loss=1.11614174, val_loss=1.42459381]\n","Validation Epoch [97/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.16it/s, val_loss=1.42333633]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97: No improvement. Patience: 2/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [98/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.90it/s, curr_train_loss=1.14454603, val_loss=1.42333633]\n","Validation Epoch [98/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.19it/s, val_loss=1.42500126]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98: No improvement. Patience: 3/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [99/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.57it/s, curr_train_loss=1.11485469, val_loss=1.42500126]\n","Validation Epoch [99/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.42601413]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99: No improvement. Patience: 4/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [100/100]: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  6.66it/s, curr_train_loss=1.17034900, val_loss=1.42601413]\n","Validation Epoch [100/100]: 100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.42257315]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: No improvement. Patience: 5/20\n","Training completed. Best model restored.\n","Model 3 Validation Accuracy: 62.00%\n","\n","============================================================\n","Training Ensemble Model 4/5\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [1/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.94it/s, curr_train_loss=2.48073888, val_loss=0.00000000]\n","Validation Epoch [1/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.30148196]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Validation loss improved to 2.301482\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [2/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.87it/s, curr_train_loss=2.45477629, val_loss=2.30148196]\n","Validation Epoch [2/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.29970980]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: Validation loss improved to 2.299710\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [3/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.91it/s, curr_train_loss=2.34894419, val_loss=2.29970980]\n","Validation Epoch [3/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=2.29855108]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: Validation loss improved to 2.298551\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [4/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=2.30472863, val_loss=2.29855108]\n","Validation Epoch [4/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=2.29699647]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: Validation loss improved to 2.296996\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [5/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.86it/s, curr_train_loss=2.31777143, val_loss=2.29699647]\n","Validation Epoch [5/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.29634285]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: Validation loss improved to 2.296343\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [6/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=2.30653250, val_loss=2.29634285]\n","Validation Epoch [6/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.29574180]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: Validation loss improved to 2.295742\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [7/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.94it/s, curr_train_loss=2.28619862, val_loss=2.29574180]\n","Validation Epoch [7/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=2.29533863]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: Validation loss improved to 2.295339\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [8/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=2.32019520, val_loss=2.29533863]\n","Validation Epoch [8/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.29399836]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8: Validation loss improved to 2.293998\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [9/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.89it/s, curr_train_loss=2.22259343, val_loss=2.29399836]\n","Validation Epoch [9/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.29326642]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: Validation loss improved to 2.293266\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [10/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=2.20297325, val_loss=2.29326642]\n","Validation Epoch [10/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.29111862]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Validation loss improved to 2.291119\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [11/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.79it/s, curr_train_loss=2.25657499, val_loss=2.29111862]\n","Validation Epoch [11/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.28975916]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: Validation loss improved to 2.289759\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [12/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.67it/s, curr_train_loss=2.17081153, val_loss=2.28975916]\n","Validation Epoch [12/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.28799605]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12: Validation loss improved to 2.287996\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [13/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.72it/s, curr_train_loss=2.13222671, val_loss=2.28799605]\n","Validation Epoch [13/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.28415906]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13: Validation loss improved to 2.284159\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [14/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=2.08226764, val_loss=2.28415906]\n","Validation Epoch [14/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.28096914]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14: Validation loss improved to 2.280969\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [15/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.56it/s, curr_train_loss=2.07746220, val_loss=2.28096914]\n","Validation Epoch [15/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.27749181]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15: Validation loss improved to 2.277492\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [16/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.83it/s, curr_train_loss=2.11705816, val_loss=2.27749181]\n","Validation Epoch [16/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.27275300]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16: Validation loss improved to 2.272753\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [17/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.37it/s, curr_train_loss=2.09047508, val_loss=2.27275300]\n","Validation Epoch [17/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.26690125]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17: Validation loss improved to 2.266901\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [18/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.98it/s, curr_train_loss=2.10345280, val_loss=2.26690125]\n","Validation Epoch [18/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.26241231]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18: Validation loss improved to 2.262412\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [19/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.35it/s, curr_train_loss=2.04265475, val_loss=2.26241231]\n","Validation Epoch [19/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.17it/s, val_loss=2.25713801]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19: Validation loss improved to 2.257138\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [20/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.88it/s, curr_train_loss=2.00103879, val_loss=2.25713801]\n","Validation Epoch [20/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.24929667]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20: Validation loss improved to 2.249297\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [21/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.85it/s, curr_train_loss=2.04148710, val_loss=2.24929667]\n","Validation Epoch [21/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.19it/s, val_loss=2.23952949]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21: Validation loss improved to 2.239529\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [22/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.02it/s, curr_train_loss=1.96841639, val_loss=2.23952949]\n","Validation Epoch [22/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.29it/s, val_loss=2.22871363]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22: Validation loss improved to 2.228714\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [23/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.70it/s, curr_train_loss=2.02258825, val_loss=2.22871363]\n","Validation Epoch [23/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=2.21704650]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23: Validation loss improved to 2.217046\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [24/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=2.00991976, val_loss=2.21704650]\n","Validation Epoch [24/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.20359874]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24: Validation loss improved to 2.203599\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [25/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.99549907, val_loss=2.20359874]\n","Validation Epoch [25/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=2.19071794]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25: Validation loss improved to 2.190718\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [26/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.89it/s, curr_train_loss=1.88839710, val_loss=2.19071794]\n","Validation Epoch [26/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=2.17644954]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26: Validation loss improved to 2.176450\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [27/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.87it/s, curr_train_loss=1.93894213, val_loss=2.17644954]\n","Validation Epoch [27/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=2.16291523]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27: Validation loss improved to 2.162915\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [28/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.92it/s, curr_train_loss=1.95284295, val_loss=2.16291523]\n","Validation Epoch [28/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.14329696]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28: Validation loss improved to 2.143297\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [29/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.92it/s, curr_train_loss=1.88493264, val_loss=2.14329696]\n","Validation Epoch [29/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=2.12415862]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29: Validation loss improved to 2.124159\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [30/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=1.76974314, val_loss=2.12415862]\n","Validation Epoch [30/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.09867799]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30: Validation loss improved to 2.098678\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [31/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.72it/s, curr_train_loss=1.82330567, val_loss=2.09867799]\n","Validation Epoch [31/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.07830429]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31: Validation loss improved to 2.078304\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [32/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=1.93082166, val_loss=2.07830429]\n","Validation Epoch [32/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.05186480]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32: Validation loss improved to 2.051865\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [33/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.91it/s, curr_train_loss=1.79136968, val_loss=2.05186480]\n","Validation Epoch [33/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=2.02975106]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33: Validation loss improved to 2.029751\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [34/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.79691356, val_loss=2.02975106]\n","Validation Epoch [34/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.25it/s, val_loss=2.00468528]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34: Validation loss improved to 2.004685\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [35/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.85it/s, curr_train_loss=1.76795828, val_loss=2.00468528]\n","Validation Epoch [35/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.97845322]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35: Validation loss improved to 1.978453\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [36/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.99it/s, curr_train_loss=1.76477653, val_loss=1.97845322]\n","Validation Epoch [36/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.95341897]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36: Validation loss improved to 1.953419\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [37/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.60it/s, curr_train_loss=1.78495812, val_loss=1.95341897]\n","Validation Epoch [37/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.92932940]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37: Validation loss improved to 1.929329\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [38/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.49it/s, curr_train_loss=1.78590000, val_loss=1.92932940]\n","Validation Epoch [38/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.90336114]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38: Validation loss improved to 1.903361\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [39/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.82it/s, curr_train_loss=1.73884904, val_loss=1.90336114]\n","Validation Epoch [39/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.87763608]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39: Validation loss improved to 1.877636\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [40/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.66it/s, curr_train_loss=1.74015331, val_loss=1.87763608]\n","Validation Epoch [40/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.85685503]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40: Validation loss improved to 1.856855\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [41/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.05it/s, curr_train_loss=1.74631065, val_loss=1.85685503]\n","Validation Epoch [41/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=1.83299565]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41: Validation loss improved to 1.832996\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [42/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.28it/s, curr_train_loss=1.66649628, val_loss=1.83299565]\n","Validation Epoch [42/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.81536692]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42: Validation loss improved to 1.815367\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [43/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.37it/s, curr_train_loss=1.70835477, val_loss=1.81536692]\n","Validation Epoch [43/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=1.79645598]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43: Validation loss improved to 1.796456\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [44/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.70it/s, curr_train_loss=1.67031556, val_loss=1.79645598]\n","Validation Epoch [44/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.78035814]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44: Validation loss improved to 1.780358\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [45/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.11it/s, curr_train_loss=1.69787073, val_loss=1.78035814]\n","Validation Epoch [45/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=1.76190388]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45: Validation loss improved to 1.761904\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [46/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.87it/s, curr_train_loss=1.63246363, val_loss=1.76190388]\n","Validation Epoch [46/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=1.74511522]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46: Validation loss improved to 1.745115\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [47/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.61617988, val_loss=1.74511522]\n","Validation Epoch [47/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.73212361]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47: Validation loss improved to 1.732124\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [48/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.66it/s, curr_train_loss=1.62059009, val_loss=1.73212361]\n","Validation Epoch [48/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.72261232]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48: Validation loss improved to 1.722612\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [49/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.75it/s, curr_train_loss=1.61498326, val_loss=1.72261232]\n","Validation Epoch [49/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.71515203]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49: Validation loss improved to 1.715152\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [50/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.05it/s, curr_train_loss=1.57077724, val_loss=1.71515203]\n","Validation Epoch [50/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.69596118]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50: Validation loss improved to 1.695961\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [51/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.66it/s, curr_train_loss=1.61745417, val_loss=1.69596118]\n","Validation Epoch [51/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.68245250]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51: Validation loss improved to 1.682452\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [52/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.31it/s, curr_train_loss=1.56546658, val_loss=1.68245250]\n","Validation Epoch [52/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.67081654]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52: Validation loss improved to 1.670817\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [53/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.86it/s, curr_train_loss=1.53767812, val_loss=1.67081654]\n","Validation Epoch [53/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=1.66408783]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53: Validation loss improved to 1.664088\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [54/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.51it/s, curr_train_loss=1.58086652, val_loss=1.66408783]\n","Validation Epoch [54/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.65479124]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54: Validation loss improved to 1.654791\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [55/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.85it/s, curr_train_loss=1.53445405, val_loss=1.65479124]\n","Validation Epoch [55/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.64760095]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55: Validation loss improved to 1.647601\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [56/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.46it/s, curr_train_loss=1.54381782, val_loss=1.64760095]\n","Validation Epoch [56/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.64219725]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56: Validation loss improved to 1.642197\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [57/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.82it/s, curr_train_loss=1.50055915, val_loss=1.64219725]\n","Validation Epoch [57/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.62944096]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57: Validation loss improved to 1.629441\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [58/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.50it/s, curr_train_loss=1.53623664, val_loss=1.62944096]\n","Validation Epoch [58/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.61588103]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58: Validation loss improved to 1.615881\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [59/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.59it/s, curr_train_loss=1.45125628, val_loss=1.61588103]\n","Validation Epoch [59/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.60707563]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59: Validation loss improved to 1.607076\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [60/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.45it/s, curr_train_loss=1.41895211, val_loss=1.60707563]\n","Validation Epoch [60/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.59295714]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60: Validation loss improved to 1.592957\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [61/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.46538812, val_loss=1.59295714]\n","Validation Epoch [61/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.58894336]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61: Validation loss improved to 1.588943\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [62/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.55it/s, curr_train_loss=1.49858868, val_loss=1.58894336]\n","Validation Epoch [62/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.17it/s, val_loss=1.57816923]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62: Validation loss improved to 1.578169\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [63/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.39887184, val_loss=1.57816923]\n","Validation Epoch [63/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.56704915]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63: Validation loss improved to 1.567049\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [64/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.54it/s, curr_train_loss=1.41260570, val_loss=1.56704915]\n","Validation Epoch [64/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.55498081]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64: Validation loss improved to 1.554981\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [65/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.70it/s, curr_train_loss=1.50424325, val_loss=1.55498081]\n","Validation Epoch [65/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.19it/s, val_loss=1.53921467]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65: Validation loss improved to 1.539215\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [66/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.83it/s, curr_train_loss=1.43566442, val_loss=1.53921467]\n","Validation Epoch [66/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.53059673]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66: Validation loss improved to 1.530597\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [67/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.06it/s, curr_train_loss=1.42949045, val_loss=1.53059673]\n","Validation Epoch [67/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.52200288]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67: Validation loss improved to 1.522003\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [68/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.94it/s, curr_train_loss=1.50906116, val_loss=1.52200288]\n","Validation Epoch [68/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.50993258]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68: Validation loss improved to 1.509933\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [69/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.40it/s, curr_train_loss=1.37232691, val_loss=1.50993258]\n","Validation Epoch [69/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=1.50679857]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69: Validation loss improved to 1.506799\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [70/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.89it/s, curr_train_loss=1.41942769, val_loss=1.50679857]\n","Validation Epoch [70/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.51it/s, val_loss=1.50187522]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70: Validation loss improved to 1.501875\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [71/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.35810608, val_loss=1.50187522]\n","Validation Epoch [71/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.49676669]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71: Validation loss improved to 1.496767\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [72/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.34515721, val_loss=1.49676669]\n","Validation Epoch [72/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.48789924]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72: Validation loss improved to 1.487899\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [73/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  7.08it/s, curr_train_loss=1.33207899, val_loss=1.48789924]\n","Validation Epoch [73/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.48228198]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73: Validation loss improved to 1.482282\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [74/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.75it/s, curr_train_loss=1.41977865, val_loss=1.48228198]\n","Validation Epoch [74/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.47462553]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74: Validation loss improved to 1.474626\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [75/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s, curr_train_loss=1.38296783, val_loss=1.47462553]\n","Validation Epoch [75/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.47371972]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75: Validation loss improved to 1.473720\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [76/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.74it/s, curr_train_loss=1.35008550, val_loss=1.47371972]\n","Validation Epoch [76/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.46732128]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76: Validation loss improved to 1.467321\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [77/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.82it/s, curr_train_loss=1.33142591, val_loss=1.46732128]\n","Validation Epoch [77/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.12it/s, val_loss=1.46678489]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77: Validation loss improved to 1.466785\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [78/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.35508436, val_loss=1.46678489]\n","Validation Epoch [78/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=1.46643275]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78: Validation loss improved to 1.466433\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [79/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s, curr_train_loss=1.29727113, val_loss=1.46643275]\n","Validation Epoch [79/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=1.46360588]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79: Validation loss improved to 1.463606\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [80/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.34269238, val_loss=1.46360588]\n","Validation Epoch [80/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=1.46190405]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80: Validation loss improved to 1.461904\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [81/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.29934669, val_loss=1.46190405]\n","Validation Epoch [81/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=1.45502269]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81: Validation loss improved to 1.455023\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [82/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.76it/s, curr_train_loss=1.20978212, val_loss=1.45502269]\n","Validation Epoch [82/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.44998908]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82: Validation loss improved to 1.449989\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [83/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.89it/s, curr_train_loss=1.25933743, val_loss=1.44998908]\n","Validation Epoch [83/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.44823122]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83: Validation loss improved to 1.448231\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [84/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.19502699, val_loss=1.44823122]\n","Validation Epoch [84/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.44570625]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84: Validation loss improved to 1.445706\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [85/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.89it/s, curr_train_loss=1.32253873, val_loss=1.44570625]\n","Validation Epoch [85/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.43848872]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85: Validation loss improved to 1.438489\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [86/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.81it/s, curr_train_loss=1.23189962, val_loss=1.43848872]\n","Validation Epoch [86/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.43267846]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86: Validation loss improved to 1.432678\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [87/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.72it/s, curr_train_loss=1.21462297, val_loss=1.43267846]\n","Validation Epoch [87/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.42146426]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87: Validation loss improved to 1.421464\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [88/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.91it/s, curr_train_loss=1.20250022, val_loss=1.42146426]\n","Validation Epoch [88/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.40722466]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88: Validation loss improved to 1.407225\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [89/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.61it/s, curr_train_loss=1.29368967, val_loss=1.40722466]\n","Validation Epoch [89/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=1.39387441]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89: Validation loss improved to 1.393874\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [90/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.84it/s, curr_train_loss=1.21531332, val_loss=1.39387441]\n","Validation Epoch [90/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.30it/s, val_loss=1.38732296]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90: Validation loss improved to 1.387323\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [91/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.16it/s, curr_train_loss=1.20120734, val_loss=1.38732296]\n","Validation Epoch [91/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.24it/s, val_loss=1.38211370]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91: Validation loss improved to 1.382114\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [92/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.08it/s, curr_train_loss=1.18124819, val_loss=1.38211370]\n","Validation Epoch [92/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=1.38058931]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92: Validation loss improved to 1.380589\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [93/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s, curr_train_loss=1.14891434, val_loss=1.38058931]\n","Validation Epoch [93/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.24it/s, val_loss=1.37530077]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93: Validation loss improved to 1.375301\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [94/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.00it/s, curr_train_loss=1.18130583, val_loss=1.37530077]\n","Validation Epoch [94/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.36155057]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94: Validation loss improved to 1.361551\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [95/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.90it/s, curr_train_loss=1.24551243, val_loss=1.36155057]\n","Validation Epoch [95/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=1.35804486]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95: Validation loss improved to 1.358045\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [96/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=1.20868284, val_loss=1.35804486]\n","Validation Epoch [96/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.29it/s, val_loss=1.35165668]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96: Validation loss improved to 1.351657\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [97/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.14926082, val_loss=1.35165668]\n","Validation Epoch [97/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.34395063]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97: Validation loss improved to 1.343951\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [98/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=1.16787624, val_loss=1.34395063]\n","Validation Epoch [98/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.34363651]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98: Validation loss improved to 1.343637\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [99/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.60it/s, curr_train_loss=1.10093802, val_loss=1.34363651]\n","Validation Epoch [99/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.34002542]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99: Validation loss improved to 1.340025\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [100/100]: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  6.86it/s, curr_train_loss=1.10657120, val_loss=1.34002542]\n","Validation Epoch [100/100]: 100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=1.33897603]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: Validation loss improved to 1.338976\n","Training completed. Best model restored.\n","Model 4 Validation Accuracy: 68.00%\n","\n","============================================================\n","Training Ensemble Model 5/5\n","============================================================\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [1/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.64it/s, curr_train_loss=2.40664482, val_loss=0.00000000]\n","Validation Epoch [1/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=2.31006944]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Validation loss improved to 2.310069\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [2/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.75it/s, curr_train_loss=2.34851635, val_loss=2.31006944]\n","Validation Epoch [2/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.30904019]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2: Validation loss improved to 2.309040\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [3/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.43it/s, curr_train_loss=2.38672733, val_loss=2.30904019]\n","Validation Epoch [3/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.30734646]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: Validation loss improved to 2.307346\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [4/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.83it/s, curr_train_loss=2.33542347, val_loss=2.30734646]\n","Validation Epoch [4/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.30572796]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4: Validation loss improved to 2.305728\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [5/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.35it/s, curr_train_loss=2.30687499, val_loss=2.30572796]\n","Validation Epoch [5/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.30441201]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: Validation loss improved to 2.304412\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [6/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.73it/s, curr_train_loss=2.22502482, val_loss=2.30441201]\n","Validation Epoch [6/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=2.30325174]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6: Validation loss improved to 2.303252\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [7/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.47it/s, curr_train_loss=2.23564756, val_loss=2.30325174]\n","Validation Epoch [7/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.52it/s, val_loss=2.30204725]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: Validation loss improved to 2.302047\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [8/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.67it/s, curr_train_loss=2.18482554, val_loss=2.30204725]\n","Validation Epoch [8/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=2.29956126]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8: Validation loss improved to 2.299561\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [9/100]: 100%|██████████████████████████████████████████| 2/2 [00:00<00:00,  6.61it/s, curr_train_loss=2.20417190, val_loss=2.29956126]\n","Validation Epoch [9/100]: 100%|████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.29719663]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: Validation loss improved to 2.297197\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [10/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=2.21194184, val_loss=2.29719663]\n","Validation Epoch [10/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.29432261]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Validation loss improved to 2.294323\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [11/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.35it/s, curr_train_loss=2.11453378, val_loss=2.29432261]\n","Validation Epoch [11/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=2.29146719]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 11: Validation loss improved to 2.291467\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [12/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.70it/s, curr_train_loss=2.08941722, val_loss=2.29146719]\n","Validation Epoch [12/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.28821325]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 12: Validation loss improved to 2.288213\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [13/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.28it/s, curr_train_loss=2.17773271, val_loss=2.28821325]\n","Validation Epoch [13/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.24it/s, val_loss=2.28618217]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 13: Validation loss improved to 2.286182\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [14/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.33it/s, curr_train_loss=2.14388824, val_loss=2.28618217]\n","Validation Epoch [14/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=2.28183830]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 14: Validation loss improved to 2.281838\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [15/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.85it/s, curr_train_loss=2.11237526, val_loss=2.28183830]\n","Validation Epoch [15/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=2.27872002]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 15: Validation loss improved to 2.278720\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [16/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.11it/s, curr_train_loss=2.04167879, val_loss=2.27872002]\n","Validation Epoch [16/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.22it/s, val_loss=2.27332640]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 16: Validation loss improved to 2.273326\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [17/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.46it/s, curr_train_loss=2.03895617, val_loss=2.27332640]\n","Validation Epoch [17/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.34it/s, val_loss=2.26705337]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 17: Validation loss improved to 2.267053\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [18/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.81it/s, curr_train_loss=2.05887747, val_loss=2.26705337]\n","Validation Epoch [18/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=2.26196420]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 18: Validation loss improved to 2.261964\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [19/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.64it/s, curr_train_loss=2.03406119, val_loss=2.26196420]\n","Validation Epoch [19/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.25524783]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 19: Validation loss improved to 2.255248\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [20/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=2.03396463, val_loss=2.25524783]\n","Validation Epoch [20/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=2.24680066]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 20: Validation loss improved to 2.246801\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [21/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.83it/s, curr_train_loss=2.02435595, val_loss=2.24680066]\n","Validation Epoch [21/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.23774004]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 21: Validation loss improved to 2.237740\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [22/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.60it/s, curr_train_loss=2.01016539, val_loss=2.23774004]\n","Validation Epoch [22/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=2.22747600]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 22: Validation loss improved to 2.227476\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [23/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.96691447, val_loss=2.22747600]\n","Validation Epoch [23/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=2.21493101]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 23: Validation loss improved to 2.214931\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [24/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.67it/s, curr_train_loss=1.95149779, val_loss=2.21493101]\n","Validation Epoch [24/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=2.20224583]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 24: Validation loss improved to 2.202246\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [25/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.76it/s, curr_train_loss=1.91761023, val_loss=2.20224583]\n","Validation Epoch [25/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=2.18919849]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 25: Validation loss improved to 2.189198\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [26/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.66it/s, curr_train_loss=1.96608531, val_loss=2.18919849]\n","Validation Epoch [26/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.42it/s, val_loss=2.17471504]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 26: Validation loss improved to 2.174715\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [27/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.88it/s, curr_train_loss=1.83662128, val_loss=2.17471504]\n","Validation Epoch [27/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.15830231]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 27: Validation loss improved to 2.158302\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [28/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.72it/s, curr_train_loss=1.85451275, val_loss=2.15830231]\n","Validation Epoch [28/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=2.14201593]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 28: Validation loss improved to 2.142016\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [29/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=1.88615143, val_loss=2.14201593]\n","Validation Epoch [29/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=2.12566996]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 29: Validation loss improved to 2.125670\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [30/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.53it/s, curr_train_loss=1.86925757, val_loss=2.12566996]\n","Validation Epoch [30/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=2.10887623]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 30: Validation loss improved to 2.108876\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [31/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.91it/s, curr_train_loss=1.88599896, val_loss=2.10887623]\n","Validation Epoch [31/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=2.08510268]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 31: Validation loss improved to 2.085103\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [32/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.49it/s, curr_train_loss=1.79631639, val_loss=2.08510268]\n","Validation Epoch [32/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.06453860]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 32: Validation loss improved to 2.064539\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [33/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s, curr_train_loss=1.92265546, val_loss=2.06453860]\n","Validation Epoch [33/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.04160851]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 33: Validation loss improved to 2.041609\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [34/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.36it/s, curr_train_loss=1.82424974, val_loss=2.04160851]\n","Validation Epoch [34/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=2.01873094]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 34: Validation loss improved to 2.018731\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [35/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.76it/s, curr_train_loss=1.74812293, val_loss=2.01873094]\n","Validation Epoch [35/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=1.99533355]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 35: Validation loss improved to 1.995334\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [36/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.60it/s, curr_train_loss=1.73470372, val_loss=1.99533355]\n","Validation Epoch [36/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.97290134]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 36: Validation loss improved to 1.972901\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [37/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.35it/s, curr_train_loss=1.72398925, val_loss=1.97290134]\n","Validation Epoch [37/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.14it/s, val_loss=1.95159441]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 37: Validation loss improved to 1.951594\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [38/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.11it/s, curr_train_loss=1.72792983, val_loss=1.95159441]\n","Validation Epoch [38/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.92942280]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 38: Validation loss improved to 1.929423\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [39/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.19it/s, curr_train_loss=1.77821660, val_loss=1.92942280]\n","Validation Epoch [39/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.15it/s, val_loss=1.90716678]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 39: Validation loss improved to 1.907167\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [40/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.79it/s, curr_train_loss=1.73903489, val_loss=1.90716678]\n","Validation Epoch [40/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.88076031]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 40: Validation loss improved to 1.880760\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [41/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.78it/s, curr_train_loss=1.64993989, val_loss=1.88076031]\n","Validation Epoch [41/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.20it/s, val_loss=1.85962290]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 41: Validation loss improved to 1.859623\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [42/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.41it/s, curr_train_loss=1.73692852, val_loss=1.85962290]\n","Validation Epoch [42/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.84137774]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 42: Validation loss improved to 1.841378\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [43/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.42it/s, curr_train_loss=1.70321941, val_loss=1.84137774]\n","Validation Epoch [43/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.82817972]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 43: Validation loss improved to 1.828180\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [44/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=1.72339553, val_loss=1.82817972]\n","Validation Epoch [44/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.81275582]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 44: Validation loss improved to 1.812756\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [45/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.65it/s, curr_train_loss=1.60369402, val_loss=1.81275582]\n","Validation Epoch [45/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.25it/s, val_loss=1.79742610]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 45: Validation loss improved to 1.797426\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [46/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.60it/s, curr_train_loss=1.63678604, val_loss=1.79742610]\n","Validation Epoch [46/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.78092122]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 46: Validation loss improved to 1.780921\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [47/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.74it/s, curr_train_loss=1.66278768, val_loss=1.78092122]\n","Validation Epoch [47/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.76629561]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 47: Validation loss improved to 1.766296\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [48/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.68it/s, curr_train_loss=1.56682020, val_loss=1.76629561]\n","Validation Epoch [48/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.75816137]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 48: Validation loss improved to 1.758161\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [49/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.42it/s, curr_train_loss=1.61677283, val_loss=1.75816137]\n","Validation Epoch [49/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.74568558]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 49: Validation loss improved to 1.745686\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [50/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.63it/s, curr_train_loss=1.58573890, val_loss=1.74568558]\n","Validation Epoch [50/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=1.73066634]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 50: Validation loss improved to 1.730666\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [51/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.64it/s, curr_train_loss=1.50776428, val_loss=1.73066634]\n","Validation Epoch [51/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.72150087]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 51: Validation loss improved to 1.721501\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [52/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.57741123, val_loss=1.72150087]\n","Validation Epoch [52/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.41it/s, val_loss=1.71283257]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 52: Validation loss improved to 1.712833\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [53/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.83it/s, curr_train_loss=1.54420346, val_loss=1.71283257]\n","Validation Epoch [53/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.70686531]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 53: Validation loss improved to 1.706865\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [54/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.93it/s, curr_train_loss=1.57430172, val_loss=1.70686531]\n","Validation Epoch [54/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.51it/s, val_loss=1.69569147]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 54: Validation loss improved to 1.695691\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [55/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.66it/s, curr_train_loss=1.54851472, val_loss=1.69569147]\n","Validation Epoch [55/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.35it/s, val_loss=1.68888307]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 55: Validation loss improved to 1.688883\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [56/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.74it/s, curr_train_loss=1.53107423, val_loss=1.68888307]\n","Validation Epoch [56/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.67716068]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 56: Validation loss improved to 1.677161\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [57/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.73it/s, curr_train_loss=1.56222510, val_loss=1.67716068]\n","Validation Epoch [57/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=1.66909170]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 57: Validation loss improved to 1.669092\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [58/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.86it/s, curr_train_loss=1.52508944, val_loss=1.66909170]\n","Validation Epoch [58/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.66294783]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 58: Validation loss improved to 1.662948\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [59/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.80it/s, curr_train_loss=1.43515664, val_loss=1.66294783]\n","Validation Epoch [59/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.65747291]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 59: Validation loss improved to 1.657473\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [60/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.81it/s, curr_train_loss=1.44655055, val_loss=1.65747291]\n","Validation Epoch [60/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.65142757]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 60: Validation loss improved to 1.651428\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [61/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.50it/s, curr_train_loss=1.51213330, val_loss=1.65142757]\n","Validation Epoch [61/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.20it/s, val_loss=1.63927656]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 61: Validation loss improved to 1.639277\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [62/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.67it/s, curr_train_loss=1.45897979, val_loss=1.63927656]\n","Validation Epoch [62/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.63139343]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 62: Validation loss improved to 1.631393\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [63/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.42it/s, curr_train_loss=1.48014426, val_loss=1.63139343]\n","Validation Epoch [63/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.61694264]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 63: Validation loss improved to 1.616943\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [64/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.18it/s, curr_train_loss=1.40040374, val_loss=1.61694264]\n","Validation Epoch [64/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.26it/s, val_loss=1.60788202]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 64: Validation loss improved to 1.607882\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [65/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.96it/s, curr_train_loss=1.40002847, val_loss=1.60788202]\n","Validation Epoch [65/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.22it/s, val_loss=1.59533042]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 65: Validation loss improved to 1.595330\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [66/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.31it/s, curr_train_loss=1.41681957, val_loss=1.59533042]\n","Validation Epoch [66/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.58930647]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 66: Validation loss improved to 1.589306\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [67/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.64it/s, curr_train_loss=1.39199632, val_loss=1.58930647]\n","Validation Epoch [67/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.57762063]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 67: Validation loss improved to 1.577621\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [68/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.97it/s, curr_train_loss=1.44882125, val_loss=1.57762063]\n","Validation Epoch [68/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.56715649]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 68: Validation loss improved to 1.567156\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [69/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.85it/s, curr_train_loss=1.29136956, val_loss=1.56715649]\n","Validation Epoch [69/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.43it/s, val_loss=1.56376553]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 69: Validation loss improved to 1.563766\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [70/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.74it/s, curr_train_loss=1.44373202, val_loss=1.56376553]\n","Validation Epoch [70/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.38it/s, val_loss=1.55891240]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 70: Validation loss improved to 1.558912\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [71/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.60it/s, curr_train_loss=1.31776029, val_loss=1.55891240]\n","Validation Epoch [71/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.36it/s, val_loss=1.55470061]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 71: Validation loss improved to 1.554701\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [72/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.71it/s, curr_train_loss=1.32705522, val_loss=1.55470061]\n","Validation Epoch [72/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.55022067]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 72: Validation loss improved to 1.550221\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [73/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.43it/s, curr_train_loss=1.38389748, val_loss=1.55022067]\n","Validation Epoch [73/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.55062503]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 73: No improvement. Patience: 1/20\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [74/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.78it/s, curr_train_loss=1.27730578, val_loss=1.55062503]\n","Validation Epoch [74/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.54315460]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 74: Validation loss improved to 1.543155\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [75/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.42it/s, curr_train_loss=1.41353530, val_loss=1.54315460]\n","Validation Epoch [75/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.53842384]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 75: Validation loss improved to 1.538424\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [76/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.62it/s, curr_train_loss=1.35084480, val_loss=1.53842384]\n","Validation Epoch [76/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.45it/s, val_loss=1.53139657]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 76: Validation loss improved to 1.531397\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [77/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.29it/s, curr_train_loss=1.31324291, val_loss=1.53139657]\n","Validation Epoch [77/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=1.52767271]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 77: Validation loss improved to 1.527673\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [78/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.63it/s, curr_train_loss=1.33593267, val_loss=1.52767271]\n","Validation Epoch [78/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.52275234]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 78: Validation loss improved to 1.522752\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [79/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.27it/s, curr_train_loss=1.34150505, val_loss=1.52275234]\n","Validation Epoch [79/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.51468217]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 79: Validation loss improved to 1.514682\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [80/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.27982426, val_loss=1.51468217]\n","Validation Epoch [80/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.33it/s, val_loss=1.50686038]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 80: Validation loss improved to 1.506860\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [81/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.46it/s, curr_train_loss=1.33729577, val_loss=1.50686038]\n","Validation Epoch [81/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.48it/s, val_loss=1.49508548]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 81: Validation loss improved to 1.495085\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [82/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.96it/s, curr_train_loss=1.19469351, val_loss=1.49508548]\n","Validation Epoch [82/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.23it/s, val_loss=1.49017978]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 82: Validation loss improved to 1.490180\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [83/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.33it/s, curr_train_loss=1.30310941, val_loss=1.49017978]\n","Validation Epoch [83/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.46it/s, val_loss=1.48418182]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 83: Validation loss improved to 1.484182\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [84/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.86it/s, curr_train_loss=1.26880848, val_loss=1.48418182]\n","Validation Epoch [84/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.31it/s, val_loss=1.47421777]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 84: Validation loss improved to 1.474218\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [85/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.92it/s, curr_train_loss=1.24778032, val_loss=1.47421777]\n","Validation Epoch [85/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.24it/s, val_loss=1.46894056]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 85: Validation loss improved to 1.468941\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [86/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.01it/s, curr_train_loss=1.20495439, val_loss=1.46894056]\n","Validation Epoch [86/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.28it/s, val_loss=1.46367967]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 86: Validation loss improved to 1.463680\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [87/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.85it/s, curr_train_loss=1.26684493, val_loss=1.46367967]\n","Validation Epoch [87/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.45736313]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 87: Validation loss improved to 1.457363\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [88/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.98it/s, curr_train_loss=1.23900115, val_loss=1.45736313]\n","Validation Epoch [88/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.27it/s, val_loss=1.45178092]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 88: Validation loss improved to 1.451781\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [89/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  5.99it/s, curr_train_loss=1.20293170, val_loss=1.45178092]\n","Validation Epoch [89/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.29it/s, val_loss=1.45122623]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 89: Validation loss improved to 1.451226\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [90/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.55it/s, curr_train_loss=1.16025472, val_loss=1.45122623]\n","Validation Epoch [90/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.44it/s, val_loss=1.44650269]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 90: Validation loss improved to 1.446503\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [91/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.69it/s, curr_train_loss=1.20221978, val_loss=1.44650269]\n","Validation Epoch [91/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.44529927]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 91: Validation loss improved to 1.445299\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [92/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.65it/s, curr_train_loss=1.16343880, val_loss=1.44529927]\n","Validation Epoch [92/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.40it/s, val_loss=1.43808758]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 92: Validation loss improved to 1.438088\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [93/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.79it/s, curr_train_loss=1.13734126, val_loss=1.43808758]\n","Validation Epoch [93/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.37it/s, val_loss=1.43039918]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 93: Validation loss improved to 1.430399\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [94/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.56it/s, curr_train_loss=1.14662206, val_loss=1.43039918]\n","Validation Epoch [94/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.39it/s, val_loss=1.42738742]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 94: Validation loss improved to 1.427387\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [95/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.57it/s, curr_train_loss=1.14299393, val_loss=1.42738742]\n","Validation Epoch [95/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.29it/s, val_loss=1.42172903]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 95: Validation loss improved to 1.421729\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [96/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.17it/s, curr_train_loss=1.18355495, val_loss=1.42172903]\n","Validation Epoch [96/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.24it/s, val_loss=1.41056496]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 96: Validation loss improved to 1.410565\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [97/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.73it/s, curr_train_loss=1.20515907, val_loss=1.41056496]\n","Validation Epoch [97/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.32it/s, val_loss=1.40157509]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 97: Validation loss improved to 1.401575\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [98/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.67it/s, curr_train_loss=1.10458344, val_loss=1.40157509]\n","Validation Epoch [98/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.49it/s, val_loss=1.39474005]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 98: Validation loss improved to 1.394740\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [99/100]: 100%|█████████████████████████████████████████| 2/2 [00:00<00:00,  6.84it/s, curr_train_loss=1.22634727, val_loss=1.39474005]\n","Validation Epoch [99/100]: 100%|███████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.47it/s, val_loss=1.38284254]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 99: Validation loss improved to 1.382843\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch [100/100]: 100%|████████████████████████████████████████| 2/2 [00:00<00:00,  6.77it/s, curr_train_loss=1.08051044, val_loss=1.38284254]\n","Validation Epoch [100/100]: 100%|██████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  9.50it/s, val_loss=1.37866771]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 100: Validation loss improved to 1.378668\n","Training completed. Best model restored.\n","Model 5 Validation Accuracy: 63.00%\n","\n","============================================================\n","Ensemble Training Complete!\n","Individual Model Accuracies: ['63.00%', '46.00%', '62.00%', '68.00%', '63.00%']\n","Average Accuracy: 60.40%\n","============================================================\n","\n","\n","Evaluating Ensemble with Test-Time Augmentation...\n","Ensemble Validation Accuracy (with TTA): \u001b[92m63.0\u001b[0m%\n","Ensemble Validation Accuracy (no TTA): 67.00%\n"]}],"source":["# Train ensemble of models for maximum accuracy\n","# This will train multiple models with different random seeds and combine their predictions\n","\n","def ensemble_predict(models, loader, use_tta=True, n_tta=10):\n","    \"\"\"\n","    Get ensemble predictions by averaging predictions from multiple models\n","\n","    Args:\n","        models: List of trained models\n","        loader: DataLoader\n","        use_tta: Whether to use test-time augmentation\n","        n_tta: Number of TTA augmentations per model\n","    \"\"\"\n","    all_scores = []\n","    all_labels = []\n","\n","    for model in models:\n","        model.eval()\n","        model = model.to(device)\n","\n","        scores = []\n","        labels = []\n","        for batch in loader:\n","            X, y = batch\n","            labels.append(y.detach().cpu().numpy())\n","\n","            X = X.to(device)\n","\n","            if use_tta:\n","                # Test-Time Augmentation\n","                batch_scores = []\n","                for _ in range(n_tta):\n","                    X_aug = model._augment_for_tta(X)\n","                    flattened_X = X_aug.view(X_aug.shape[0], -1)\n","                    with torch.no_grad():\n","                        score = model.forward(flattened_X)\n","                    batch_scores.append(score.detach().cpu().numpy())\n","                score = np.mean(batch_scores, axis=0)\n","            else:\n","                flattened_X = X.view(X.shape[0], -1)\n","                with torch.no_grad():\n","                    score = model.forward(flattened_X)\n","                score = score.detach().cpu().numpy()\n","\n","            scores.append(score)\n","\n","        all_scores.append(np.concatenate(scores, axis=0))\n","        # Collect labels only once (from first model iteration)\n","        if len(all_labels) == 0:\n","            all_labels = np.concatenate(labels, axis=0)\n","\n","    # Average predictions from all models\n","    ensemble_scores = np.mean(all_scores, axis=0)\n","    preds = ensemble_scores.argmax(axis=1)\n","    acc = (all_labels == preds).mean()\n","\n","    return preds, acc\n","\n","print(\"=\"*60)\n","print(\"TRAINING ENSEMBLE FOR MAXIMUM ACCURACY\")\n","print(\"=\"*60)\n","print(\"This will train multiple models - it will take time but gives best results!\")\n","print(\"=\"*60)\n","\n","# Create tensorboard logger for ensemble\n","path = os.path.join('logs', 'ensemble_logs')\n","num_of_runs = len(os.listdir(path)) if os.path.exists(path) else 0\n","path = os.path.join(path, f'run_{num_of_runs + 1}')\n","tb_logger_ensemble = SummaryWriter(path)\n","\n","# Train ensemble with pretrained encoders\n","from exercise_code.models import Classifier, Encoder\n","from copy import deepcopy\n","\n","ensemble_models = []\n","best_accs = []\n","n_ensemble_models = 5  # Increase to 7-10 for even better results (but takes longer)\n","\n","for i in range(n_ensemble_models):\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Training Ensemble Model {i+1}/{n_ensemble_models}\")\n","    print(f\"{'='*60}\")\n","\n","    # Use different random seed for each model\n","    torch.manual_seed(42 + i * 100)\n","    np.random.seed(42 + i * 100)\n","\n","    # Use pretrained encoder (copy it for each model)\n","    encoder_pretrained_copy = deepcopy(encoder_pretrained)\n","    classifier = Classifier(hparams, encoder_pretrained_copy).to(device)\n","\n","    # Train this model\n","    train_classifier(classifier, labled_train_loader, labled_val_loader, loss_func, tb_logger_ensemble,\n","                    epochs=hparams.get('epochs', 100), name=f\"Ensemble_Pretrained_model_{i+1}\",\n","                    early_stopping_patience=20, min_delta=1e-5)\n","\n","    # Evaluate\n","    val_acc = classifier.getAcc(labled_val_loader)[1] * 100\n","    print(f\"Model {i+1} Validation Accuracy: {val_acc:.2f}%\")\n","\n","    ensemble_models.append(deepcopy(classifier))\n","    best_accs.append(val_acc)\n","\n","print(f\"\\n{'='*60}\")\n","print(f\"Ensemble Training Complete!\")\n","print(f\"Individual Model Accuracies: {[f'{acc:.2f}%' for acc in best_accs]}\")\n","print(f\"Average Accuracy: {np.mean(best_accs):.2f}%\")\n","print(f\"{'='*60}\\n\")\n","\n","# Evaluate ensemble with TTA\n","print(\"\\nEvaluating Ensemble with Test-Time Augmentation...\")\n","val_acc_ensemble = ensemble_predict(ensemble_models, labled_val_loader, use_tta=True, n_tta=20)[1] * 100\n","color = 'green' if val_acc_ensemble > 55 else 'red'\n","print(f\"Ensemble Validation Accuracy (with TTA): {bcolors.colorize(color, val_acc_ensemble)}%\")\n","\n","# Also evaluate without TTA for comparison\n","val_acc_ensemble_no_tta = ensemble_predict(ensemble_models, labled_val_loader, use_tta=False)[1] * 100\n","print(f\"Ensemble Validation Accuracy (no TTA): {val_acc_ensemble_no_tta:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"H-pm1MY_MNks"},"source":["Let's have a look at the validation accuracy of the two different classifiers and compare them. And don't forget that you can also monitor your training in TensorBoard.\n","\n","We will only look at the test accuracy and compare our two classifiers with respect to that in the very end."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-e5Bd9KLMNkt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767639997945,"user_tz":-60,"elapsed":214,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"}},"outputId":"398101c1-1746-41e4-bd39-482773dbff00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validation accuracy when training from scratch: \u001b[92m63.0\u001b[0m%\n","Validation accuracy with pretraining: \u001b[91m44.0\u001b[0m%\n"]}],"source":["val_acc_scracth = classifier.getAcc(labled_val_loader)[1]*100\n","color = 'green' if val_acc_scracth > 55 else 'red'\n","print(f\"Validation accuracy when training from scratch: {bcolors.colorize(color, val_acc_scracth)}%\")\n","\n","val_acc_pretrained = classifier_pretrained.getAcc(labled_val_loader)[1]*100\n","color = 'green' if val_acc_pretrained > 55 else 'red'\n","print(f\"Validation accuracy with pretraining: {bcolors.colorize(color, val_acc_pretrained)}%\")\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zAp2OTyf4_5b"},"source":["Now that everything is working, feel free to play around with different architectures. As you've seen, it's quite easy to define your model or do adpations there.\n","\n","To pass this submission, you will need to achieve an accuracy of **55%**."]},{"cell_type":"markdown","metadata":{"id":"OmEYmRT-5S-e"},"source":["# Save your model & Report Test Accuracy\n","\n","When you are finally done with your **hyperparameter tuning**, achieved **at least 55% validation accuracy** and are happy with your final model, you can save it here.\n","\n","Before that, please check again whether the number of parameters is below 5 Mio and the file size is below 20 MB.\n","\n","Once your final model is saved, we'll finally report the test accuracy."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"MXKRSeiav0nA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767639998017,"user_tz":-60,"elapsed":63,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"}},"outputId":"115a77a2-b54a-4b10-e324-95ffae49bc6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ensemble and TTA functions loaded!\n"]}],"source":["# Train autoencoder with early stopping - train longer for better representations\n","# ADVANCED TECHNIQUES FOR 98%+ ACCURACY\n","# Train autoencoder with early stopping - train longer for better representations\n","\n","def train_ensemble_models(hparams, train_loader, val_loader, loss_func, tb_logger,\n","                          n_models=5, epochs=100, name=\"Ensemble\"):\n","    \"\"\"\n","    Train multiple models with different random seeds for ensemble\n","\n","    Args:\n","        n_models: Number of models to train\n","        epochs: Number of epochs per model\n","    \"\"\"\n","    from exercise_code.models import Classifier, Encoder\n","    from copy import deepcopy\n","\n","    models = []\n","    best_accs = []\n","\n","    for i in range(n_models):\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Training Ensemble Model {i+1}/{n_models}\")\n","        print(f\"{'='*60}\")\n","\n","        # Use different random seed for each model\n","        torch.manual_seed(42 + i * 100)\n","        np.random.seed(42 + i * 100)\n","\n","        # Create new encoder and classifier\n","        encoder = Encoder(hparams).to(device)\n","        classifier = Classifier(hparams, encoder).to(device)\n","\n","        # Train this model\n","        train_classifier(classifier, train_loader, val_loader, loss_func, tb_logger,\n","                        epochs=epochs, name=f\"{name}_model_{i+1}\",\n","                        early_stopping_patience=20, min_delta=1e-5)\n","\n","        # Evaluate\n","        val_acc = classifier.getAcc(val_loader)[1] * 100\n","        print(f\"Model {i+1} Validation Accuracy: {val_acc:.2f}%\")\n","\n","        models.append(deepcopy(classifier))\n","        best_accs.append(val_acc)\n","\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Ensemble Training Complete!\")\n","    print(f\"Individual Model Accuracies: {[f'{acc:.2f}%' for acc in best_accs]}\")\n","    print(f\"Average Accuracy: {np.mean(best_accs):.2f}%\")\n","    print(f\"{'='*60}\\n\")\n","\n","    return models\n","\n","def ensemble_predict(models, loader, use_tta=True, n_tta=10):\n","    \"\"\"\n","    Get ensemble predictions by averaging predictions from multiple models\n","\n","    Args:\n","        models: List of trained models\n","        loader: DataLoader\n","        use_tta: Whether to use test-time augmentation\n","        n_tta: Number of TTA augmentations per model\n","    \"\"\"\n","    all_scores = []\n","    labels = None\n","\n","    for model in models:\n","        model.eval()\n","        model = model.to(device)\n","\n","        scores = []\n","        for batch in loader:\n","            X, y = batch\n","            if labels is None:\n","                labels = y.detach().cpu().numpy()\n","\n","            X = X.to(device)\n","\n","            if use_tta:\n","                # Test-Time Augmentation\n","                batch_scores = []\n","                for _ in range(n_tta):\n","                    X_aug = model._augment_for_tta(X)\n","                    flattened_X = X_aug.view(X_aug.shape[0], -1)\n","                    with torch.no_grad():\n","                        score = model.forward(flattened_X)\n","                    batch_scores.append(score.detach().cpu().numpy())\n","                score = np.mean(batch_scores, axis=0)\n","            else:\n","                flattened_X = X.view(X.shape[0], -1)\n","                with torch.no_grad():\n","                    score = model.forward(flattened_X)\n","                score = score.detach().cpu().numpy()\n","\n","            scores.append(score)\n","\n","        all_scores.append(np.concatenate(scores, axis=0))\n","\n","    # Average predictions from all models\n","    ensemble_scores = np.mean(all_scores, axis=0)\n","    preds = ensemble_scores.argmax(axis=1)\n","    acc = (labels == preds).mean()\n","\n","    return preds, acc\n","\n","print(\"Ensemble and TTA functions loaded!\")\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"S69ETKxD5TcE","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767639999902,"user_tz":-60,"elapsed":1884,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"}},"outputId":"12cd358b-8d4c-4365-f13c-d8a3433424b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy when training from scratch: \u001b[92m66.0\u001b[0m%\n","Test accuracy with pretraining: \u001b[91m50.0\u001b[0m%\n","Validation Accuracy: \u001b[91m44.0\u001b[0m%\n","# Parameters: Your model has \u001b[92m0.619\u001b[0m mio. params.\n","Size: Great! Your model size is \u001b[92m4.8\u001b[0m MB and is less than 20 MB.\n","Your model has been saved and is ready to be submitted.\n"]}],"source":["from exercise_code.Util import test_and_save\n","test_dl = torch.utils.data.DataLoader(test_100_dataset, batch_size=4, shuffle=False)\n","\n","test_acc = classifier.getAcc(test_dl)[1]*100\n","color = 'green' if test_acc > 55 else 'red'\n","print(f\"Test accuracy when training from scratch: {bcolors.colorize(color, test_acc)}%\")\n","\n","test_acc = classifier_pretrained.getAcc(test_dl)[1]*100\n","color = 'green' if test_acc > 55 else 'red'\n","print(f\"Test accuracy with pretraining: {bcolors.colorize(color, test_acc)}%\")\n","\n","test_and_save(classifier_pretrained, labled_val_loader, test_dl)"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"enZCnGL6MNkt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1767640007786,"user_tz":-60,"elapsed":7883,"user":{"displayName":"Ahmet Yasin Erten","userId":"15999106896806149378"}},"outputId":"4ce1658f-2be0-4a6e-8342-b7393dc1759d"},"outputs":[{"output_type":"stream","name":"stdout","text":["relevant folders: ['exercise_code', 'models']\n","notebooks files: ['Optional-BatchNormalization_Dropout.ipynb', 'backup.ipynb', 'temp_restore.ipynb', '1_Autoencoder.ipynb']\n","Adding folder exercise_code\n","Adding folder models\n","Adding notebook Optional-BatchNormalization_Dropout.ipynb\n","Adding notebook backup.ipynb\n","Adding notebook temp_restore.ipynb\n","Adding notebook 1_Autoencoder.ipynb\n","Zipping successful! Zip is stored under: /content/gdrive/MyDrive/i2dl/output/exercise_08.zip\n"]}],"source":["# Now zip the folder for upload\n","from exercise_code.submit import submit_exercise\n","\n","submit_exercise('../output/exercise_08')"]},{"cell_type":"markdown","metadata":{"id":"7fuo3Tf9MNku"},"source":["Congratulations on completing your first autoencoder and successfully transferring the weights to a classifier! It's remarkable how much easier this process becomes with the power of PyTorch, compared to working with plain NumPy, right?\n","\n","To complete the exercise, please submit your final model to [our submission portal](https://i2dl.vc.in.tum.de/) - you should be already familiar with the submission procedure. Next, it is time to get started with some more complex neural networks and tasks in the upcoming exercises. See you next week!\n","\n","# Submission Goals\n","\n","- Goal: Successfully implement a fully connected autoencoder for MNIST with Pytorch and transfer the encoder weights to a classifier.\n","\n","- Passing Criteria: There are no unit tests that check specific components of your code. The only thing that's required to pass the submission, is your model to reach at least **55% accuracy** on __our__ test dataset. The submission system will show you a number between 0 and 100 which corresponds to your accuracy.\n","\n","\n","- You can make **$\\infty$** submissions until the deadline. Your __best submission__ will be considered for the bonus."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"runtime_attributes":{"runtime_version":"2025.07"}},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":0}